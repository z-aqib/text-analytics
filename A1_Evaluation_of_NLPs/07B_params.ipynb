{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries\n",
    "performing all necessary imports here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T12:15:06.255354Z",
     "iopub.status.busy": "2025-02-02T12:15:06.255050Z",
     "iopub.status.idle": "2025-02-02T12:15:26.522932Z",
     "shell.execute_reply": "2025-02-02T12:15:26.522102Z",
     "shell.execute_reply.started": "2025-02-02T12:15:06.255321Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import model related libraries\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# import huggingface login\n",
    "from huggingface_hub import login\n",
    "\n",
    "# import the accesstoken of huggingface, which is saved in .env file\n",
    "# from dotenv import load_dotenv # it was not running on kaggle so i have commented it\n",
    "import os\n",
    "\n",
    "# import time to compute how long it took the model to run\n",
    "import time\n",
    "\n",
    "# import date-time to display the date and time of last run\n",
    "from datetime import datetime\n",
    "\n",
    "# import text wrap to make sure its fully displayable\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Inputs\n",
    "here we initailize all inputs given, like the input text, the prompt, and the model name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Text\n",
    "here is the email we will be passing for all models: this is given in the question and stays constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T12:15:26.524247Z",
     "iopub.status.busy": "2025-02-02T12:15:26.523734Z",
     "iopub.status.idle": "2025-02-02T12:15:26.529158Z",
     "shell.execute_reply": "2025-02-02T12:15:26.528366Z",
     "shell.execute_reply.started": "2025-02-02T12:15:26.524223Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:\n",
      " Subject: Concerns About Professor X’s Conduct \n",
      " \n",
      "Dear Dr. Ustaad, \n",
      "I hope this email finds you well. I am writing to express my concerns about Professor X’s conduct during the Introduction to Zoology class last semester. On multiple occasions, Professor X made dismissive remarks about students’ questions and failed to provide clear feedback on assignments.  \n",
      " \n",
      "Additionally, the grading seemed inconsistent and unfair, with no opportunity for clarification or appeal. \n",
      " \n",
      "I found this experience deeply frustrating and demotivating, and I believe it affected my performance in the course. I would appreciate it if the department could look into this matter and ensure that future students have a more positive and supportive learning environment. \n",
      " \n",
      "Thank you for your attention to this matter. \n",
      "Sincerely, \n",
      "Shaagird\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"Subject: Concerns About Professor X’s Conduct \n",
    " \n",
    "Dear Dr. Ustaad, \n",
    "I hope this email finds you well. I am writing to express my concerns about Professor X’s conduct during the Introduction to Zoology class last semester. On multiple occasions, Professor X made dismissive remarks about students’ questions and failed to provide clear feedback on assignments.  \n",
    " \n",
    "Additionally, the grading seemed inconsistent and unfair, with no opportunity for clarification or appeal. \n",
    " \n",
    "I found this experience deeply frustrating and demotivating, and I believe it affected my performance in the course. I would appreciate it if the department could look into this matter and ensure that future students have a more positive and supportive learning environment. \n",
    " \n",
    "Thank you for your attention to this matter. \n",
    "Sincerely, \n",
    "Shaagird\n",
    "\"\"\"\n",
    "\n",
    "print(\"Input Text:\\n\", input_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Params\n",
    "here we intialize the model name, its parameters, and then the text_generator we will be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T12:15:26.530215Z",
     "iopub.status.busy": "2025-02-02T12:15:26.529936Z",
     "iopub.status.idle": "2025-02-02T12:22:12.457785Z",
     "shell.execute_reply": "2025-02-02T12:22:12.457117Z",
     "shell.execute_reply.started": "2025-02-02T12:15:26.530194Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875df0a2692a4cef88e3fed6a6d9d5ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/733 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e09a8520984099b2abb910df697fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/27.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a159127af4404b7abf6ac9920a3e2096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e363c97030b4b5089067c2017007240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.88G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0bcf54a1214288b96201569c116165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91536d9727b844b5a25d093b0a205e35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370edaff5a1f489caf36387dcae7aff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0fb3f3b7666485aa445f5942ec3515b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531cf8df0a1f4dcb8dbfc46a38fdcebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/243 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c140b4ad689d49038eda41d562ccd8d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21156640b0e247279e7cb39525ed8c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6e6a5de3214dc8b0baf8aee8bbccee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8294f8ce5f147ae9b7b58e02fcff53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e6f51e4128445ddabc9d4d5190f4b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c003c2a296854498bea04fc0d062f6e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"open-thoughts/OpenThinker-7B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T12:22:12.458766Z",
     "iopub.status.busy": "2025-02-02T12:22:12.458553Z",
     "iopub.status.idle": "2025-02-02T12:22:12.464909Z",
     "shell.execute_reply": "2025-02-02T12:22:12.464110Z",
     "shell.execute_reply.started": "2025-02-02T12:22:12.458747Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=5000,\n",
    "    do_sample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login, Authentication\n",
    "here we authenticate the hugging face access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T12:22:12.465851Z",
     "iopub.status.busy": "2025-02-02T12:22:12.465613Z",
     "iopub.status.idle": "2025-02-02T12:22:12.480980Z",
     "shell.execute_reply": "2025-02-02T12:22:12.480197Z",
     "shell.execute_reply.started": "2025-02-02T12:22:12.465829Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# first we load the access token from the .env hidden file (it is a gitignore file)\n",
    "# load_dotenv() # it was not running on kaggle so i have commentated it\n",
    "# api_token = os.getenv(\"HUGGINGFACE_API_TOKEN\")\n",
    "api_token = \"\" # put your api token here, have removed for github security"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T12:22:12.483344Z",
     "iopub.status.busy": "2025-02-02T12:22:12.483096Z",
     "iopub.status.idle": "2025-02-02T12:22:12.580202Z",
     "shell.execute_reply": "2025-02-02T12:22:12.579433Z",
     "shell.execute_reply.started": "2025-02-02T12:22:12.483324Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "login(api_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Running\n",
    "here we run the model, but before that we display the model details and also compute the timetaken to run the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Details\n",
    "here we display how many parameters and how much memory the model took"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T12:22:12.581463Z",
     "iopub.status.busy": "2025-02-02T12:22:12.581242Z",
     "iopub.status.idle": "2025-02-02T12:22:12.587479Z",
     "shell.execute_reply": "2025-02-02T12:22:12.586724Z",
     "shell.execute_reply.started": "2025-02-02T12:22:12.581443Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.bfloat16\n",
      "Model Total Parameters: 7.62 billion\n",
      "Estimate Memory Footprint: 14525.64 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.dtype)\n",
    "\n",
    "# Parameters Computation\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model Total Parameters: {total_params / 1e9:.2f} billion\")\n",
    "\n",
    "# Memory used Computation (in MBs)\n",
    "memory = total_params * 2 / (1024 ** 2)  \n",
    "print(f\"Estimate Memory Footprint: {memory:.2f} MB\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Running\n",
    "here for every task, we will first save the start_time and the end_time and then compute the timetaken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T12:22:12.588519Z",
     "iopub.status.busy": "2025-02-02T12:22:12.588261Z",
     "iopub.status.idle": "2025-02-02T12:22:12.602031Z",
     "shell.execute_reply": "2025-02-02T12:22:12.601238Z",
     "shell.execute_reply.started": "2025-02-02T12:22:12.588498Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def compute_time(start_time, end_time):\n",
    "    \"\"\"This function calculates the time difference between two given times in seconds. For this given problem, this function computes the timetaken by a model to run and perform a task\n",
    "\n",
    "    Args:\n",
    "        start_time (time): start time of the model\n",
    "        end_time (time): end time of the model\n",
    "\n",
    "    Returns:\n",
    "        string: the time taken in hours, minutes, seconds, and mili-seconds\n",
    "    \"\"\"\n",
    "    elapsed_time = end_time - start_time\n",
    "    hours, rem = divmod(elapsed_time, 3600)\n",
    "    minutes, rem = divmod(rem, 60)\n",
    "    seconds, milliseconds = divmod(rem, 1)\n",
    "    milliseconds *= 1000  # Convert seconds fraction to milliseconds\n",
    "    \n",
    "    return f\"Time taken: {int(hours)}h {int(minutes)}m {int(seconds)}s {int(milliseconds)}ms\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Making\n",
    "here we define the prompt we will use for all tasks of summarization, question answering, keyword extraction and translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T12:22:12.603070Z",
     "iopub.status.busy": "2025-02-02T12:22:12.602789Z",
     "iopub.status.idle": "2025-02-02T12:22:12.616566Z",
     "shell.execute_reply": "2025-02-02T12:22:12.615768Z",
     "shell.execute_reply.started": "2025-02-02T12:22:12.603049Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Perform the following actions: \n",
    "1 - Summarize the following text delimited by triple backticks.\n",
    "2 - Answer “What was the reason for the student's disappointment with Professor X? ” based on the email content.\n",
    "3 - Identify key details such as incidents, concerns, and requested actions. \n",
    "4 - Translate the following text into French.\n",
    "\n",
    "Separate your answers with line breaks.\n",
    "Text:\n",
    "```{input_text}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Execution\n",
    "here we run the model by passing the prompt to a text_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T12:22:12.617446Z",
     "iopub.status.busy": "2025-02-02T12:22:12.617249Z",
     "iopub.status.idle": "2025-02-02T12:23:31.935295Z",
     "shell.execute_reply": "2025-02-02T12:23:31.934453Z",
     "shell.execute_reply.started": "2025-02-02T12:22:12.617428Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:650: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0h 1m 19s 304ms\n",
      "Output:\n",
      " Answer 1:\n",
      "The email expresses concerns about Professor X's conduct in the Introduction to Zoology class. The student describes dismissive remarks towards questions and inconsistent/unfair grading without opportunities for clarification or appeal. This led to frustration and decreased motivation, impacting their performance. They request an investigation to improve future student experiences.\n",
      "\n",
      "Answer 2:\n",
      "The student was disappointed with Professor X due to dismissive remarks about their questions and unfair, inconsistent grading without avenues for clarification or appeal, which demotivated them and harmed their course performance.\n",
      "\n",
      "Answer 3:\n",
      "Key details include:\n",
      "- Multiple instances of dismissive remarks from Professor X.\n",
      "- Inconsistent and unfair grading practices.\n",
      "- Lack of opportunities for clarification or appeal regarding grades.\n",
      "- Impact on the student's motivation and performance.\n",
      "- Request for departmental intervention to address these issues.\n",
      "\n",
      "Answer 4:\n",
      "Objet : Inquiétudes concernant le comportement du Professeur X\n",
      "\n",
      "Cher Dr. Ustaad,\n",
      "\n",
      "J'espère que ce courriel vous trouve en bonne santé. Je vous écris pour exprimer mes inquiétudes concernant le comportement du Professeur X lors de la classe d'introduction à la zoologie l'an dernier. À plusieurs reprises, le Professeur X a fait des remarques dédaigneuses envers les questions des étudiants et n'a pas fourni de retour sur leurs devoirs de manière claire et constructive.\n",
      "\n",
      "De plus, la notation semblait inconsistante et injuste, sans aucune opportunité de clarification ou d'appel. \n",
      "\n",
      "Cette expérience m'a troublé et a miné ma motivation, ce qui a affecté mon rendement dans le cours. J'apprécierais que le département examine cette situation et s'assure d'un environnement d'apprentissage plus positif et soutenant pour les futurs étudiants.\n",
      "\n",
      "Je vous remercie pour votre attention à ce sujet.\n",
      "\n",
      "Cordialement,\n",
      "Shaagird\n",
      "\n",
      "<|begin_of_thought|>\n",
      "\n",
      "Okay, let's tackle this task step by step. First, summarizing the text. The email is from a student named Shaagird to Dr. Ustaad, complaining about Professor X's behavior in a zoology class. The main points are that Professor X dismissed students' questions and didn't give clear assignment feedback. Grading was inconsistent and unfair, with no chance to clarify or appeal. The student felt frustrated and demotivated, affecting their performance. They want the department to look into it.\n",
      "\n",
      "For the second question, the reason for disappointment is clear from the text: dismissive remarks and unfair grading without options for clarification or appeal. That's the core issue leading to demotivation and poor performance.\n",
      "\n",
      "Third, key details: incidents (dismissive remarks, inconsistent grading), concerns (demotivation, performance impact), and requested action (departmental investigation).\n",
      "\n",
      "Fourth, translating into French. Need to maintain the original tone and structure. Check grammar and vocabulary, especially technical terms like \"grading\" and \"appeal.\" Also, make sure the translation is natural in French academic context.\n",
      "\n",
      "<|end_of_thought|>\n",
      "\n",
      "<|begin_of_solution|>\n",
      "\n",
      "**Summary:**  \n",
      "A student expresses concerns about Professor X's dismissive teaching style and unfair grading in an introductory zoology class. The student felt demotivated, impacting their performance and seeks departmental intervention to improve future student experiences.\n",
      "\n",
      "**Answer to Question 2:**  \n",
      "The student was disappointed because Professor X dismissed their questions and graded inconsistently without allowing clarification or appeals, leading to frustration and reduced motivation.\n",
      "\n",
      "**Key Details Identified:**  \n",
      "- **Incidents:** Dismissive remarks, inconsistent/unfair grading.  \n",
      "- **Concerns:** Demotivation, performance decline.  \n",
      "- **Requested Actions:** Departmental investigation to address issues and ensure a supportive learning environment.\n",
      "\n",
      "**French Translation:**  \n",
      "Objet : Inquiétudes concernant le comportement du Professeur X  \n",
      "\n",
      "Cher Dr. Ustaad,  \n",
      "\n",
      "J'espère que ce courriel vous trouve en bonne santé. Je vous écris pour exprimer mes inquiétudes concernant le comportement du Professeur X lors de la classe d'introduction à la zoologie l'an dernier. À plusieurs reprises, le Professeur X a fait des remarques dédaigneuses envers les questions des étudiants et n'a pas fourni de retour sur leurs devoirs de manière claire et constructive.  \n",
      "\n",
      "De plus, la notation semblait inconsistante et injuste, sans aucune opportunité de clarification ou d'appel.  \n",
      "\n",
      "Cette expérience m'a troublé et a miné ma motivation, ce qui a affecté mon rendement dans le cours. J'apprécierais que le département examine cette situation et s'assure d'un environnement d'apprentissage plus positif et soutenant pour les futurs étudiants.  \n",
      "\n",
      "Je vous remercie pour votre attention à ce sujet.  \n",
      "\n",
      "Cordialement,  \n",
      "Shaagird\n",
      "\n",
      "<|end_of_solution|>\n"
     ]
    }
   ],
   "source": [
    "# start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# generate the output\n",
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": prompt}\n",
    "# ]\n",
    "output = generator(prompt)\n",
    "\n",
    "# end the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# display time taken with output\n",
    "print(compute_time(start_time, end_time))\n",
    "print(\"Output:\\n\", output[0][\"generated_text\"])#textwrap.fill(output[0][\"generated_text\"], width=80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T12:25:32.206771Z",
     "iopub.status.busy": "2025-02-02T12:25:32.206481Z",
     "iopub.status.idle": "2025-02-02T12:25:32.210529Z",
     "shell.execute_reply": "2025-02-02T12:25:32.209748Z",
     "shell.execute_reply.started": "2025-02-02T12:25:32.206748Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompt_back_to_eng = \"\"\"\n",
    "Translate the following text to English:\n",
    "Objet : Inquiétudes concernant le comportement du Professeur X  \n",
    "\n",
    "Cher Dr. Ustaad,  \n",
    "\n",
    "J'espère que ce courriel vous trouve en bonne santé. Je vous écris pour exprimer mes inquiétudes concernant le comportement du Professeur X lors de la classe d'introduction à la zoologie l'an dernier. À plusieurs reprises, le Professeur X a fait des remarques dédaigneuses envers les questions des étudiants et n'a pas fourni de retour sur leurs devoirs de manière claire et constructive.  \n",
    "\n",
    "De plus, la notation semblait inconsistante et injuste, sans aucune opportunité de clarification ou d'appel.  \n",
    "\n",
    "Cette expérience m'a troublé et a miné ma motivation, ce qui a affecté mon rendement dans le cours. J'apprécierais que le département examine cette situation et s'assure d'un environnement d'apprentissage plus positif et soutenant pour les futurs étudiants.  \n",
    "\n",
    "Je vous remercie pour votre attention à ce sujet.  \n",
    "\n",
    "Cordialement,  \n",
    "Shaagird\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T12:25:34.987276Z",
     "iopub.status.busy": "2025-02-02T12:25:34.986900Z",
     "iopub.status.idle": "2025-02-02T12:26:54.711844Z",
     "shell.execute_reply": "2025-02-02T12:26:54.711081Z",
     "shell.execute_reply.started": "2025-02-02T12:25:34.987246Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0h 1m 19s 720ms\n",
      "Output:\n",
      " Subject: Concerns about Professor X's Behavior\n",
      "\n",
      "Dear Dr. Ustaad,\n",
      "\n",
      "I hope this email finds you well. I am writing to express my concerns regarding the behavior of Professor X during last year's Introduction to Zoology class. On multiple occasions, Professor X made derogatory comments towards student questions and failed to provide clear and constructive feedback on their assignments.\n",
      "\n",
      "Moreover, the grading appeared inconsistent and unfair, with no opportunity for clarification or appeal.\n",
      "\n",
      "This experience has troubled me and diminished my motivation, impacting my performance in the course. I would appreciate it if the department could review this situation and ensure a more positive and supportive learning environment for future students.\n",
      "\n",
      "Thank you for your attention to this matter.\n",
      "\n",
      "Sincerely,\n",
      "Student\n",
      "<|begin_of_thought|>\n",
      "\n",
      "Okay, let's see. The original text is in French, and I need to translate it into English. First, I should read through the entire message to understand the context and the key points. The subject line is \"Inquiétudes concernant le comportement du Professeur X\" which translates to \"Concerns about Professor X's Behavior.\" \n",
      "\n",
      "The email is from a student (referred to as \"Shaagird\") to Dr. Ustaad, likely an academic administrator or department head. The main issues raised are Professor X's derogatory remarks towards students' questions, lack of clear and constructive feedback on assignments, inconsistent and unfair grading, and the resulting negative impact on the student's motivation and performance.\n",
      "\n",
      "Breaking down each part:\n",
      "\n",
      "1. **Subject Line**: Direct translation.\n",
      "2. **Greeting**: \"Cher Dr. Ustaad\" becomes \"Dear Dr. Ustaad.\"\n",
      "3. **First paragraph**: Expressing hope for Dr. Ustaad's health, then stating the purpose of the email—concerns about Professor X's behavior in a zoology class last year.\n",
      "4. **Body of the email**:\n",
      "   - Multiple instances of Professor X making derogatory comments about student questions.\n",
      "   - Lack of clear and constructive feedback on assignments.\n",
      "   - Grading inconsistency and unfairness without opportunities for clarification or appeal.\n",
      "5. **Impact**: Troubled experience leading to decreased motivation and affected performance.\n",
      "6. **Conclusion**: Request for the department to examine the situation and improve the learning environment for future students.\n",
      "\n",
      "Potential translation challenges:\n",
      "- Ensuring the tone remains formal and professional.\n",
      "- Translating \"Professeur X\" as \"Professor X\" since it's a placeholder name.\n",
      "- Maintaining the structure and flow of the original message while adapting to English syntax.\n",
      "\n",
      "Key terms to translate accurately:\n",
      "- \"Inquiétudes\" = Concerns\n",
      "- \"comportement\" = behavior\n",
      "- \"remarques dédaigneuses\" = derogatory comments\n",
      "- \"retour sur leurs devoirs\" = feedback on their assignments\n",
      "- \"notation semblait inconsistante et injuste\" = grading appeared inconsistent and unfair\n",
      "- \" Opportunité de clarification ou d'appel\" = opportunity for clarification or appeal\n",
      "\n",
      "After translating each section, I'll check for any cultural nuances or expressions that might not translate directly but still convey the intended meaning. For example, \"Cher Dr. Ustaad\" uses \"Cher\" which is formal, appropriate for an academic setting. The closing \"Cordialement\" is also formal and suitable.\n",
      "\n",
      "Final check: Ensure that the translated email maintains the original's urgency and polite request for action. The student is expressing concerns constructively and seeking resolution rather than complaint.\n",
      "\n",
      "<|end_of_thought|>\n",
      "\n",
      "<|begin_of_solution|>\n",
      "\n",
      "**Subject:** Concerns about Professor X's Behavior  \n",
      "\n",
      "**Dear Dr. Ustaad,**  \n",
      "\n",
      "I hope this message finds you well. I am writing to express my concerns regarding the behavior of Professor X during last year’s Introduction to Zoology class. On multiple occasions, Professor X made derogatory comments toward student questions and failed to provide clear, constructive feedback on assignments.  \n",
      "\n",
      "**Key Issues:**  \n",
      "- **Derogatory Comments:** Professor X dismissed student inquiries with disdain, undermining classroom engagement.  \n",
      "- **Grading Inconsistency:** Grades seemed arbitrary and unjustified, with no avenues for clarification or appeal.  \n",
      "- **Impact on Motivation:** This experience diminished my enthusiasm, negatively affecting my coursework performance.  \n",
      "\n",
      "**Request:**  \n",
      "I kindly ask the department to investigate this situation and work toward creating a more positive, supportive learning environment for future students.  \n",
      "\n",
      "**Thank you** for addressing this matter.  \n",
      "\n",
      "**Sincerely,**  \n",
      "Shaagird  \n",
      "\n",
      "---\n",
      "\n",
      "**Translation Justification:**  \n",
      "- **Formal Tone:** Uses \"Cher Dr. Ustaad\" and \"Cordialement\" to maintain professionalism.  \n",
      "- **Precise Terminology:** Translates \"inquiétudes\" as \"concerns,\" \"remarques dédaigneuses\" as \"derogatory comments,\" and \"notation\" as \"grading.\"  \n",
      "- **Contextual Adjustments:** Rewrote \"Objet\" as \"Subject\" and streamlined the structure to fit English conventions.  \n",
      "\n",
      "This translation preserves the original intent while ensuring clarity and formality.\n",
      "\n",
      "<|end_of_solution|>\n"
     ]
    }
   ],
   "source": [
    "# start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# generate the output\n",
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": prompt_back_to_eng}\n",
    "# ]\n",
    "output = generator(prompt_back_to_eng)\n",
    "\n",
    "# end the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# display time taken with output\n",
    "print(compute_time(start_time, end_time))\n",
    "print(\"Output:\\n\", output[0][\"generated_text\"])#textwrap.fill(output[0][\"generated_text\"], width=80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End\n",
    "here we display the last time this jupyter notebook was run to always remember it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T12:26:54.713062Z",
     "iopub.status.busy": "2025-02-02T12:26:54.712795Z",
     "iopub.status.idle": "2025-02-02T12:26:54.717226Z",
     "shell.execute_reply": "2025-02-02T12:26:54.716520Z",
     "shell.execute_reply.started": "2025-02-02T12:26:54.713039Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-02 12:26:54\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
