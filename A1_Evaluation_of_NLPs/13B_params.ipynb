{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries. \nperforming all necessary imports here","metadata":{}},{"cell_type":"code","source":"# import model related libraries\nfrom transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n\n# import huggingface login\nfrom huggingface_hub import login\n\n# import the accesstoken of huggingface, which is saved in .env file\n# from dotenv import load_dotenv # it was not running on kaggle so i have commented it\nimport os\n\n# import time to compute how long it took the model to run\nimport time\n\n# import date-time to display the date and time of last run\nfrom datetime import datetime\n\n# import text wrap to make sure its fully displayable\nimport textwrap\n\n# import torch as we want to set its datatype as this is a larger model\nimport torch","metadata":{"execution":{"iopub.status.busy":"2025-02-02T17:20:26.091363Z","iopub.execute_input":"2025-02-02T17:20:26.091634Z","iopub.status.idle":"2025-02-02T17:20:48.081174Z","shell.execute_reply.started":"2025-02-02T17:20:26.091603Z","shell.execute_reply":"2025-02-02T17:20:48.080341Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# Initialize Inputs\nhere we initailize all inputs given, like the input text, the prompt, and the model name","metadata":{}},{"cell_type":"markdown","source":"### Input Text\nhere is the email we will be passing for all models: this is given in the question and stays constant","metadata":{}},{"cell_type":"code","source":"input_text = \"\"\"Subject: Concerns About Professor X’s Conduct \n \nDear Dr. Ustaad, \nI hope this email finds you well. I am writing to express my concerns about Professor X’s conduct during the Introduction to Zoology class last semester. On multiple occasions, Professor X made dismissive remarks about students’ questions and failed to provide clear feedback on assignments.  \n \nAdditionally, the grading seemed inconsistent and unfair, with no opportunity for clarification or appeal. \n \nI found this experience deeply frustrating and demotivating, and I believe it affected my performance in the course. I would appreciate it if the department could look into this matter and ensure that future students have a more positive and supportive learning environment. \n \nThank you for your attention to this matter. \nSincerely, \nShaagird\n\"\"\"\n\nprint(\"Input Text:\\n\", input_text)","metadata":{"execution":{"iopub.status.busy":"2025-02-02T17:20:48.082022Z","iopub.execute_input":"2025-02-02T17:20:48.082592Z","iopub.status.idle":"2025-02-02T17:20:48.087195Z","shell.execute_reply.started":"2025-02-02T17:20:48.082567Z","shell.execute_reply":"2025-02-02T17:20:48.086459Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Input Text:\n Subject: Concerns About Professor X’s Conduct \n \nDear Dr. Ustaad, \nI hope this email finds you well. I am writing to express my concerns about Professor X’s conduct during the Introduction to Zoology class last semester. On multiple occasions, Professor X made dismissive remarks about students’ questions and failed to provide clear feedback on assignments.  \n \nAdditionally, the grading seemed inconsistent and unfair, with no opportunity for clarification or appeal. \n \nI found this experience deeply frustrating and demotivating, and I believe it affected my performance in the course. I would appreciate it if the department could look into this matter and ensure that future students have a more positive and supportive learning environment. \n \nThank you for your attention to this matter. \nSincerely, \nShaagird\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Model Params\nhere we intialize the model name, its parameters, and then the text_generator we will be using","metadata":{}},{"cell_type":"code","source":"model_name = \"microsoft/phi-4\"\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    device_map=\"auto\",\n    torch_dtype=\"auto\",\n    trust_remote_code=True\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2025-02-02T17:20:48.088110Z","iopub.execute_input":"2025-02-02T17:20:48.088424Z","iopub.status.idle":"2025-02-02T17:34:28.657138Z","shell.execute_reply.started":"2025-02-02T17:20:48.088396Z","shell.execute_reply":"2025-02-02T17:34:28.656228Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/820 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8a9fc31630148bcbb1885814722e537"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/20.4k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"628669a269154042a8b19c4f37734981"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41a68856f34f4fc1b44de2b6c71af40e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00006.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ef8fb8158fa4c0bb6b621d35cdb67a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00006.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a8ff61d5ff348dbb5a7d44f38447b3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00006.safetensors:   0%|          | 0.00/4.90G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14658c7ec3794213b43888ba513dddce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00006.safetensors:   0%|          | 0.00/4.77G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a92b826a24e44839b22324185f11e95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00005-of-00006.safetensors:   0%|          | 0.00/4.77G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54b713fec466440ca73af028aab689f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00006-of-00006.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad1c8ece5c164ea48810843ea2402fa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12b9ffc7a2f04f44a2d922c4f7aa2c54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/156 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4ee41ac6e5344a138612922a256442f4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/17.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e8f4aa97a454b97b917d24a00f5cc8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.61M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42b0e1c0342349ba87245b5ba22cfa5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/917k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15fb4ea0fb494ae1a89cce9717f784df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/4.25M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"634d95e81dbd49b8bbb5eb34f70b5c51"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.50k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3ccfbd2ed48404ca98183a682eaa871"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c002fdc12fd44d78d29fa06daa01f2d"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"generator = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    return_full_text=False,\n    max_new_tokens=5000,\n    do_sample=False\n)","metadata":{"execution":{"iopub.status.busy":"2025-02-02T17:34:28.659331Z","iopub.execute_input":"2025-02-02T17:34:28.659634Z","iopub.status.idle":"2025-02-02T17:34:28.665854Z","shell.execute_reply.started":"2025-02-02T17:34:28.659612Z","shell.execute_reply":"2025-02-02T17:34:28.665177Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Login, Authentication\nhere we authenticate the hugging face access token","metadata":{}},{"cell_type":"code","source":"# first we load the access token from the .env hidden file (it is a gitignore file)\n# load_dotenv() # it was not running on kaggle so i have commentated it\n# api_token = os.getenv(\"HUGGINGFACE_API_TOKEN\")\napi_token = \"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\"# put your api token here, have removed for github security","metadata":{"execution":{"iopub.status.busy":"2025-02-02T17:34:28.667107Z","iopub.execute_input":"2025-02-02T17:34:28.667414Z","iopub.status.idle":"2025-02-02T17:34:28.680767Z","shell.execute_reply.started":"2025-02-02T17:34:28.667392Z","shell.execute_reply":"2025-02-02T17:34:28.680140Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"login(api_token)","metadata":{"execution":{"iopub.status.busy":"2025-02-02T17:34:28.681441Z","iopub.execute_input":"2025-02-02T17:34:28.681637Z","iopub.status.idle":"2025-02-02T17:34:28.952667Z","shell.execute_reply.started":"2025-02-02T17:34:28.681613Z","shell.execute_reply":"2025-02-02T17:34:28.951884Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Model Running\nhere we run the model, but before that we display the model details and also compute the timetaken to run the model","metadata":{}},{"cell_type":"markdown","source":"### Model Details\nhere we display how many parameters and how much memory the model took","metadata":{}},{"cell_type":"code","source":"print(model.dtype)\n\n# Parameters Computation\ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f\"Model Total Parameters: {total_params / 1e9:.2f} billion\")\n\n# Memory used Computation (in MBs)\nmemory = total_params * 2 / (1024 ** 2)  \nprint(f\"Estimate Memory Footprint: {memory:.2f} MB\\n\")","metadata":{"execution":{"iopub.status.busy":"2025-02-02T17:34:28.953483Z","iopub.execute_input":"2025-02-02T17:34:28.953743Z","iopub.status.idle":"2025-02-02T17:34:28.961957Z","shell.execute_reply.started":"2025-02-02T17:34:28.953716Z","shell.execute_reply":"2025-02-02T17:34:28.961224Z"},"trusted":true},"outputs":[{"name":"stdout","text":"torch.bfloat16\nModel Total Parameters: 14.66 billion\nEstimate Memory Footprint: 27960.79 MB\n\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"## Model Running\nhere for every task, we will first save the start_time and the end_time and then compute the timetaken","metadata":{}},{"cell_type":"code","source":"def compute_time(start_time, end_time):\n    \"\"\"This function calculates the time difference between two given times in seconds. For this given problem, this function computes the timetaken by a model to run and perform a task\n\n    Args:\n        start_time (time): start time of the model\n        end_time (time): end time of the model\n\n    Returns:\n        string: the time taken in hours, minutes, seconds, and mili-seconds\n    \"\"\"\n    elapsed_time = end_time - start_time\n    hours, rem = divmod(elapsed_time, 3600)\n    minutes, rem = divmod(rem, 60)\n    seconds, milliseconds = divmod(rem, 1)\n    milliseconds *= 1000  # Convert seconds fraction to milliseconds\n    \n    return f\"Time taken: {int(hours)}h {int(minutes)}m {int(seconds)}s {int(milliseconds)}ms\"","metadata":{"execution":{"iopub.status.busy":"2025-02-02T17:34:28.962741Z","iopub.execute_input":"2025-02-02T17:34:28.963030Z","iopub.status.idle":"2025-02-02T17:34:28.976570Z","shell.execute_reply.started":"2025-02-02T17:34:28.963010Z","shell.execute_reply":"2025-02-02T17:34:28.975791Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"### Prompt Making\nhere we define the prompt we will use for all tasks of summarization, question answering, keyword extraction and translation","metadata":{}},{"cell_type":"code","source":"prompt = f\"\"\"\nPerform the following actions: \n1 - Summarize the following text delimited by triple backticks.\n2 - Answer “What was the reason for the student's disappointment with Professor X? ” based on the email content.\n3 - Identify key details such as incidents, concerns, and requested actions. \n4 - Translate the following text into French.\n\nSeparate your answers with line breaks.\nText:\n```{input_text}```\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2025-02-02T17:34:28.977356Z","iopub.execute_input":"2025-02-02T17:34:28.977594Z","iopub.status.idle":"2025-02-02T17:34:28.991377Z","shell.execute_reply.started":"2025-02-02T17:34:28.977563Z","shell.execute_reply":"2025-02-02T17:34:28.990593Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Model Execution\nhere we run the model by passing the prompt to a text_generator","metadata":{}},{"cell_type":"code","source":"# start the timer\nstart_time = time.time()\n\nsummarization_prompt = f\"summarize the following text:\\n\\n{input_text}\\n\\nSummary:\"\nsummarization_response = generator(summarization_prompt, max_new_tokens=150, num_return_sequences=1)\nsummarized_text = summarization_response[0]['generated_text'].split(\"Summary:\")[-1].strip()\n\n# 2. Question Answering\nquestion = \"What was the reason for the student's disappointment with Professor X?\"\nquestion_prompt = f\"Context: {input_text}\\n\\nQuestion: {question}\\n\\nAnswer:\"\nanswer_response = generator(question_prompt, max_new_tokens=200, num_return_sequences=1)\nanswer_extracted = answer_response[0]['generated_text']\n\n# 3. Keyword Extraction\nkeyword_prompt = f\"Extract important keywords from the following text:\\n\\n{input_text}\\n\\nKeywords:\"\nkeyword_response = generator(keyword_prompt, max_new_tokens=350, num_return_sequences=1)\nkeyword_extracted = keyword_response[0]['generated_text'].split(\"Keywords:\")[-1].strip()\n\n# 4. Translation to French and Back to English\ntranslation_prompt = f\"Translate the following English text into French:\\n\\n{input_text}\\n\\nFrench Translation:\\n\\nNow, translate the French text back into English:\\n\\nFrench Text:\"\n# Use text generation to get the French translation and then translate it back to English\ntranslation_response = generator(translation_prompt, max_new_tokens=375, num_return_sequences=1)\ntranslated_text = translation_response[0]['generated_text'].split(\"French Translation:\")[-1].split(\"French Text:\")[-1].strip()\n\n# end the timer\nend_time = time.time()\n\n# display time taken with output\nprint(compute_time(start_time, end_time))\n# print(\"Output:\\n\", output[0][\"generated_text\"])#textwrap.fill(output[0][\"generated_text\"], width=80))\nprint(\"\\nSummarized Text:\", summarized_text)\nprint(\"\\nAnswer to the question:\", answer_extracted)\nprint(\"\\nExtracted Keywords:\", keyword_extracted)\nprint(\"\\nTranslated Text:\", translated_text)","metadata":{"execution":{"iopub.status.busy":"2025-02-02T17:35:22.641141Z","iopub.execute_input":"2025-02-02T17:35:22.641474Z","iopub.status.idle":"2025-02-02T17:36:45.440483Z","shell.execute_reply.started":"2025-02-02T17:35:22.641448Z","shell.execute_reply":"2025-02-02T17:36:45.439605Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Time taken: 0h 1m 22s 791ms\n\nSummarized Text: The student, Shaagird, is expressing concerns about Professor X’s conduct in the Introduction to Zoology class. Shaagird mentions that Professor X made dismissive remarks, failed to provide clear feedback, and had inconsistent grading. Shaagird found the experience frustrating and demotivating, affecting their performance. They request the department to investigate and improve the learning environment for future students.\n\n\n## response\n\nThe student, Shaagird, is writing to Dr. Ustaad to express concerns about Professor X's conduct in the Introduction to Zoology class. Shaagird reports that Professor X made dismissive remarks, failed to provide clear feedback on assignments, and had inconsistent and unfair grading. This experience was frustrating and demotivating for Shaag\n\nAnswer to the question:  The student was disappointed with Professor X because of dismissive remarks about students’ questions, lack of clear feedback on assignments, inconsistent and unfair grading, and no opportunity for clarification or appeal.\n\nExtracted Keywords: \n\nTranslated Text: Objet: Préoccupations concernant le comportement du Professeur X \n\nCher Dr. Ustaad, \nJ'espère que ce courriel vous trouve en bonne santé. Je vous écris pour exprimer mes préoccupations concernant le comportement du Professeur X lors du cours d'introduction à la zoologie l'année dernière. À plusieurs reprises, le Professeur X a fait des remarques dédaigneuses sur les questions des étudiants et a échoué à fournir des commentaires clairs sur les devoirs. \n\nDe plus, la notation semblait incohérente et injuste, sans possibilité de clarification ou d'appel. \n\nJ'ai trouvé cette expérience profondément frustrante et démoralisante, et je crois qu'elle a affecté ma performance dans le cours. J'apprécierais que le département examine cette affaire et assure que les futurs étudiants aient un environnement d'apprentissage plus positif et soutenant. \n\nMerci de votre attention à cette affaire. \nCordialement, \nShaagird\n\nEnglish Translation:\n\n## Solution: English Text:\n\nSubject: Concerns About Professor X’s Conduct\n\nDear Dr. Ustaad,\n\nI hope this email finds you well. I am writing to express my concerns about Professor X’s conduct during the Introduction to Zoology class last semester. On multiple occasions, Professor X made dismissive remarks about students’ questions and failed to provide clear feedback on assignments.\n\nAdditionally, the grading seemed inconsistent and unfair, with no opportunity for clarification or appeal.\n\nI found this experience deeply frustrating and demotivating, and I believe it affected my performance in the course. I would appreciate it if the department could look into this\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"prompt_back_to_eng = \"\"\"\nTranslate the following text to English:\nTranslated Text: Objet: Préoccupations concernant le comportement du Professeur X \n\nCher Dr. Ustaad, \nJ'espère que ce courriel vous trouve en bonne santé. Je vous écris pour exprimer mes préoccupations concernant le comportement du Professeur X lors du cours d'introduction à la zoologie l'année dernière. À plusieurs reprises, le Professeur X a fait des remarques dédaigneuses sur les questions des étudiants et a échoué à fournir des commentaires clairs sur les devoirs. \n\nDe plus, la notation semblait incohérente et injuste, sans possibilité de clarification ou d'appel. \n\nJ'ai trouvé cette expérience profondément frustrante et démoralisante, et je crois qu'elle a affecté ma performance dans le cours. J'apprécierais que le département examine cette affaire et assure que les futurs étudiants aient un environnement d'apprentissage plus positif et soutenant. \n\nMerci de votre attention à cette affaire. \nCordialement, \nShaagird\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2025-02-02T17:41:41.687189Z","iopub.execute_input":"2025-02-02T17:41:41.687511Z","iopub.status.idle":"2025-02-02T17:41:41.691291Z","shell.execute_reply.started":"2025-02-02T17:41:41.687488Z","shell.execute_reply":"2025-02-02T17:41:41.690330Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# start the timer\nstart_time = time.time()\n\n# generate the output\nmessages = [\n    {\"role\": \"user\", \"content\": prompt_back_to_eng}\n]\noutput = generator(messages)\n\n# end the timer\nend_time = time.time()\n\n# display time taken with output\nprint(compute_time(start_time, end_time))\nprint(\"Output:\\n\", output[0][\"generated_text\"])#textwrap.fill(output[0][\"generated_text\"], width=80))","metadata":{"execution":{"iopub.status.busy":"2025-02-02T17:41:41.692229Z","iopub.execute_input":"2025-02-02T17:41:41.692425Z","iopub.status.idle":"2025-02-02T17:42:05.572863Z","shell.execute_reply.started":"2025-02-02T17:41:41.692408Z","shell.execute_reply":"2025-02-02T17:42:05.572105Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Time taken: 0h 0m 23s 863ms\nOutput:\n **Subject: Concerns Regarding Professor X's Behavior**\n\nDear Dr. Ustaad,\n\nI hope this email finds you in good health. I am writing to express my concerns about Professor X's behavior during last year's introductory zoology course. On several occasions, Professor X made dismissive remarks about students' questions and failed to provide clear feedback on assignments.\n\nAdditionally, the grading seemed inconsistent and unfair, with no opportunity for clarification or appeal.\n\nI found this experience deeply frustrating and demoralizing, and I believe it affected my performance in the course. I would appreciate it if the department could examine this matter and ensure that future students have a more positive and supportive learning environment.\n\nThank you for your attention to this matter.\n\nSincerely,  \nShaagird\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# End\nhere we display the last time this jupyter notebook was run to always remember it","metadata":{}},{"cell_type":"code","source":"print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))","metadata":{"execution":{"iopub.status.busy":"2025-02-02T17:42:05.573784Z","iopub.execute_input":"2025-02-02T17:42:05.573998Z","iopub.status.idle":"2025-02-02T17:42:05.578024Z","shell.execute_reply.started":"2025-02-02T17:42:05.573980Z","shell.execute_reply":"2025-02-02T17:42:05.577303Z"},"trusted":true},"outputs":[{"name":"stdout","text":"2025-02-02 17:42:05\n","output_type":"stream"}],"execution_count":20}]}