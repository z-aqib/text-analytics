{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11345061,"sourceType":"datasetVersion","datasetId":7098504},{"sourceId":11439657,"sourceType":"datasetVersion","datasetId":7166003},{"sourceId":11439662,"sourceType":"datasetVersion","datasetId":7166008}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Acknowledgement\nName: Hamna Inam, Zara Masood, Zuha Aqib     \nERP ID: X, Y, 26106    \nSection: 10am Miss Solat    \nDate: 16-Apr-25   ","metadata":{"id":"j1D1m381Ebv5"}},{"cell_type":"code","source":"from datetime import datetime\nprint(\"Last time code executed:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:01:31.657611Z","iopub.execute_input":"2025-04-19T18:01:31.658204Z","iopub.status.idle":"2025-04-19T18:01:31.665106Z","shell.execute_reply.started":"2025-04-19T18:01:31.658181Z","shell.execute_reply":"2025-04-19T18:01:31.664418Z"},"id":"pBYgXkK-EbwD","outputId":"6369c243-79e2-4398-e457-b4b88e418973","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"name":"stdout","text":"Last time code executed: 2025-04-19 18:01:31\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"def print_date_time():\n    return \"\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:01:31.666174Z","iopub.execute_input":"2025-04-19T18:01:31.666828Z","iopub.status.idle":"2025-04-19T18:01:31.686357Z","shell.execute_reply.started":"2025-04-19T18:01:31.666806Z","shell.execute_reply":"2025-04-19T18:01:31.685669Z"},"id":"CXAQ2BwVEbwH"},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Imports\nhere we add all imports and prerequisities like installations, authentications, constant definitions etc","metadata":{"id":"4d8Us0HHEbwJ"}},{"cell_type":"markdown","source":"## Installations\nfirst we need to install related packages","metadata":{"id":"sm79L72bEbwJ"}},{"cell_type":"code","source":"# # adding this because kaggle ke maslay\n# !pip uninstall -y langchain langchain-core langchain-community langchain-openai ragas pydantic -y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:01:31.687348Z","iopub.execute_input":"2025-04-19T18:01:31.687590Z","iopub.status.idle":"2025-04-19T18:01:31.702369Z","shell.execute_reply.started":"2025-04-19T18:01:31.687566Z","shell.execute_reply":"2025-04-19T18:01:31.701897Z"},"id":"1wF3_bZqEbwK"},"outputs":[],"execution_count":3},{"cell_type":"code","source":"get_ipython().system('pip install transformers')\nget_ipython().system('pip install sentence-transformers')\nget_ipython().system('pip install pypdf')\nget_ipython().system('pip install pymupdf')\nget_ipython().system('pip install rank_bm25')\nget_ipython().system('pip install datasets')\nget_ipython().system('pip install matplotlib')\nget_ipython().system('pip install faiss')\nget_ipython().system('pip install faiss-cpu')\nget_ipython().system('pip install faiss-gpu')\nget_ipython().system('pip install --upgrade pypdf')\n\n# 2. Then install\n# !pip install \"langchain==0.2.0\"\n# !pip install \"langchain-core==0.2.0\"\n# !pip install \"langchain-community==0.2.0\"\n# !pip install \"langchain-text-splitters==0.2.1\"\n# !pip install \"langchain-openai==0.1.0\"\n# !pip install \"pydantic==2.6.4\"\n# !pip install \"ragas==0.2.14\"\n\n!pip install langchain\n!pip install langchain-core\n!pip install langchain-community\n!pip install langchain-text-splitters\n!pip install langchain-openai\n!pip install pydantic\n!pip install ragas\n\n!pip install --upgrade pandas","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:01:31.703307Z","iopub.execute_input":"2025-04-19T18:01:31.703579Z","iopub.status.idle":"2025-04-19T18:03:50.706299Z","shell.execute_reply.started":"2025-04-19T18:01:31.703557Z","shell.execute_reply":"2025-04-19T18:03:50.705567Z"},"id":"RgO_gHo1EbwL","outputId":"fa4d0f38-c3e4-4d9e-e624-1469d46bbea9","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nRequirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\nCollecting pymupdf\n  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\nDownloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymupdf\nSuccessfully installed pymupdf-1.25.5\nCollecting rank_bm25\n  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rank_bm25) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rank_bm25) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rank_bm25) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rank_bm25) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rank_bm25) (2024.2.0)\nDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\nInstalling collected packages: rank_bm25\nSuccessfully installed rank_bm25-0.2.2\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2024.12.0\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.20->matplotlib) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\n\u001b[31mERROR: Could not find a version that satisfies the requirement faiss (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for faiss\u001b[0m\u001b[31m\n\u001b[0mCollecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nDownloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.10.0\n\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\nRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.18)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.34 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.35)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.38)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.16)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\nRequirement already satisfied: numpy<2,>=1.26.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.19.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.34->langchain) (4.13.1)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.26.4->langchain) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.26.4->langchain) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.26.4->langchain) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.26.4->langchain) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.26.4->langchain) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.26.4->langchain) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain) (3.0.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.26.4->langchain) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.26.4->langchain) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2,>=1.26.4->langchain) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\nRequirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.35)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (0.3.8)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.0.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (6.0.2)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.13.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.11.3)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (3.10.15)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (2.32.3)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.4.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (0.14.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core) (2.3.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core) (1.3.1)\nCollecting langchain-community\n  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\nCollecting langchain-core<1.0.0,>=0.3.51 (from langchain-community)\n  Downloading langchain_core-0.3.54-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain<1.0.0,>=0.3.23 (from langchain-community)\n  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.16)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.8)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nCollecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.23->langchain-community)\n  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.1)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2.4.1)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.2->langchain-community) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\nDownloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.54-py3-none-any.whl (433 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\nDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nInstalling collected packages: python-dotenv, httpx-sse, pydantic-settings, langchain-core, langchain-text-splitters, langchain, langchain-community\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.35\n    Uninstalling langchain-core-0.3.35:\n      Successfully uninstalled langchain-core-0.3.35\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.6\n    Uninstalling langchain-text-splitters-0.3.6:\n      Successfully uninstalled langchain-text-splitters-0.3.6\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.18\n    Uninstalling langchain-0.3.18:\n      Successfully uninstalled langchain-0.3.18\nSuccessfully installed httpx-sse-0.4.0 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.54 langchain-text-splitters-0.3.8 pydantic-settings-2.9.1 python-dotenv-1.1.0\nRequirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.11/dist-packages (0.3.8)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain-text-splitters) (0.3.54)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (0.3.8)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (9.0.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (1.33)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (6.0.2)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (4.13.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (2.11.3)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (3.10.15)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (2.32.3)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (0.4.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (0.14.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (2.3.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.51->langchain-text-splitters) (1.3.1)\nCollecting langchain-openai\n  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.53 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.3.54)\nCollecting openai<2.0.0,>=1.68.2 (from langchain-openai)\n  Downloading openai-1.75.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (0.3.8)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (9.0.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (1.33)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (6.0.2)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (4.13.1)\nRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.53->langchain-openai) (2.11.3)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.8.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.68.2->langchain-openai) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.68.2->langchain-openai) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.53->langchain-openai) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain-openai) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain-openai) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.53->langchain-openai) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain-openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain-openai) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.53->langchain-openai) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.3.0)\nDownloading langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openai-1.75.0-py3-none-any.whl (646 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: openai, langchain-openai\n  Attempting uninstall: openai\n    Found existing installation: openai 1.61.1\n    Uninstalling openai-1.61.1:\n      Successfully uninstalled openai-1.61.1\nSuccessfully installed langchain-openai-0.3.14 openai-1.75.0\nRequirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.3)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.13.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.0)\nCollecting ragas\n  Downloading ragas-0.2.14-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ragas) (1.26.4)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from ragas) (3.5.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ragas) (0.9.0)\nRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.23)\nRequirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.54)\nRequirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.21)\nRequirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (from ragas) (0.3.14)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ragas) (1.6.0)\nCollecting appdirs (from ragas)\n  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: pydantic>=2 in /usr/local/lib/python3.11/dist-packages (from ragas) (2.11.3)\nRequirement already satisfied: openai>1 in /usr/local/lib/python3.11/dist-packages (from ragas) (1.75.0)\nCollecting diskcache>=5.6.3 (from ragas)\n  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (0.8.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (4.13.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas) (0.4.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->ragas) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (3.11.16)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (6.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->ragas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->ragas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->ragas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->ragas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->ragas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->ragas) (2.4.1)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas) (0.3.8)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas) (0.3.8)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas) (2.0.38)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core->ragas) (9.0.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core->ragas) (1.33)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community->ragas) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->ragas) (2.9.1)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community->ragas) (0.4.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->ragas) (2024.11.6)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (1.19.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas) (3.10)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (0.23.0)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas) (1.1.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->ragas) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->ragas) (2.3.0)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.1.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ragas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ragas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->ragas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->ragas) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas) (2025.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->ragas) (2024.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.17.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.0.0)\nDownloading ragas-0.2.14-py3-none-any.whl (187 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\nInstalling collected packages: appdirs, diskcache, ragas\nSuccessfully installed appdirs-1.4.4 diskcache-5.6.3 ragas-0.2.14\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas) (2024.2.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"!pip install numpy==1.26.4 scipy==1.12.0 --force-reinstall","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:03:50.708007Z","iopub.execute_input":"2025-04-19T18:03:50.708536Z","iopub.status.idle":"2025-04-19T18:04:03.003965Z","shell.execute_reply.started":"2025-04-19T18:03:50.708511Z","shell.execute_reply":"2025-04-19T18:04:03.003065Z"}},"outputs":[{"name":"stdout","text":"Collecting numpy==1.26.4\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting scipy==1.12.0\n  Downloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading scipy-1.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: numpy, scipy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.26.4\n    Uninstalling numpy-1.26.4:\n      Successfully uninstalled numpy-1.26.4\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.15.2\n    Uninstalling scipy-1.15.2:\n      Successfully uninstalled scipy-1.15.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\nnilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nibis-framework 9.2.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed numpy-1.26.4 scipy-1.12.0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## Imports\nhere we import the necessary libraries and modules","metadata":{"id":"RAKtxVv0EbwN"}},{"cell_type":"code","source":"# ===== Environment & Authentication =====\nimport os\nimport time\nimport csv\n# from dotenv import load_dotenv, dotenv_values\nfrom huggingface_hub import login\n\n# ===== Core Python & Data Handling =====\nfrom typing import List, Tuple, Dict\nimport textwrap\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# ===== NLP Preprocessing =====\nimport nltk\nfrom rank_bm25 import BM25Okapi  # BM25 retriever\nnltk.download('punkt')  # Ensure NLTK data is available\n\n# ===== LangChain - Document Loading & Splitting =====\nfrom langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n# from langchain.schema import Document\nfrom langchain_core.documents import Document\n\n# ===== LangChain - Embeddings & Vector Stores =====\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\n\n# ===== Hugging Face Models & Pipelines =====\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    pipeline\n)\nfrom langchain.llms import (\n    HuggingFaceHub,\n    HuggingFacePipeline\n)\n\n# ===== RAG Evaluation (RAGAS) =====\nfrom ragas import evaluate\nfrom ragas.metrics import (\n    Faithfulness,\n    AnswerRelevancy,\n    ContextRecall,\n    ContextPrecision,\n    AnswerCorrectness\n)\nfrom datasets import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:03.005300Z","iopub.execute_input":"2025-04-19T18:04:03.005573Z","iopub.status.idle":"2025-04-19T18:04:29.350214Z","shell.execute_reply.started":"2025-04-19T18:04:03.005540Z","shell.execute_reply":"2025-04-19T18:04:29.349631Z"},"id":"22QiRs-aEbwO","outputId":"e8156eed-7734-44fd-dd53-13af7ed8951c","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n2025-04-19 18:04:16.008817: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745085856.200280      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745085856.253116      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# because there was an error in this import, here it is seperatly\nimport torch\nprint(torch.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.351685Z","iopub.execute_input":"2025-04-19T18:04:29.352144Z","iopub.status.idle":"2025-04-19T18:04:29.355968Z","shell.execute_reply.started":"2025-04-19T18:04:29.352126Z","shell.execute_reply":"2025-04-19T18:04:29.355389Z"},"id":"ITlgZo5AEbwO","outputId":"5fb80a8e-862d-4fd4-9af5-a32ee3ff448d","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"name":"stdout","text":"2.5.1+cu124\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from packaging import version\n\n# Check torch version (modern alternative)\ndef is_torch_greater_or_equal_than_1_13():\n    return version.parse(torch.__version__) >= version.parse(\"1.13.0\")\n\nprint(f\"Torch version: {torch.__version__}\")\nprint(f\"Is >=1.13.0: {is_torch_greater_or_equal_than_1_13()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.356618Z","iopub.execute_input":"2025-04-19T18:04:29.356939Z","iopub.status.idle":"2025-04-19T18:04:29.522087Z","shell.execute_reply.started":"2025-04-19T18:04:29.356918Z","shell.execute_reply":"2025-04-19T18:04:29.521352Z"},"id":"oJxxudGdEbwP","outputId":"db0e5a54-0c21-49bc-da90-1b8786681a88","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"name":"stdout","text":"Torch version: 2.5.1+cu124\nIs >=1.13.0: True\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Authentication\nhere we authenticate our LLM with hugging face","metadata":{"id":"KRG7BTmKEbwP"}},{"cell_type":"code","source":"# # Load environment variables from .env\n# load_dotenv()\n\n# # Retrieve the token\n# hf_token = os.getenv(\"HUGGING_FACE_TOKEN\")\n\n# print(\"Token loaded:\", hf_token is not None)\n\n# # Log in to Hugging Face Hub\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.522773Z","iopub.execute_input":"2025-04-19T18:04:29.523021Z","iopub.status.idle":"2025-04-19T18:04:29.617473Z","shell.execute_reply.started":"2025-04-19T18:04:29.522998Z","shell.execute_reply":"2025-04-19T18:04:29.617019Z"},"id":"F0yPasmAEbwP"},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# config = dotenv_values(\".env\")\n# login(token=config[\"HUGGING_FACE_TOKEN\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.618121Z","iopub.execute_input":"2025-04-19T18:04:29.618347Z","iopub.status.idle":"2025-04-19T18:04:29.621766Z","shell.execute_reply.started":"2025-04-19T18:04:29.618325Z","shell.execute_reply":"2025-04-19T18:04:29.621152Z"},"id":"rqAqPx9_EbwQ"},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"## Constants\nhere we define constants that we will fine tune","metadata":{"id":"mwpZZH72EbwQ"}},{"cell_type":"code","source":"# Constants\nDEFAULT_CHUNK_SIZE = 1000              # Max size of each text chunk\nDEFAULT_CHUNK_OVERLAP = 200            # Overlap between chunks\nDEFAULT_SEARCH_K = 3                   # Top-k results to retrieve\nDEFAULT_SEARCH_TYPE = \"hybrid\"         # Choose from: 'semantic', 'keyword', or 'hybrid'\nDEFAULT_EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # Embedding model for vector search\n#DEFAULT_LLM_MODEL = \"meta-llama/Llama-3.2-1B\"   #worked!\n# DEFAULT_LLM_MODEL = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\" # worked!\n\n# DEFAULT_LLM_MODEL = \"microsoft/phi-2\"   #worked\n# DEFAULT_LLM_MODEL = \"mistralai/Mistral-7B-Instruct-v0.2\" #out of memory error\n# DEFAULT_LLM_MODEL = \"google/gemma-1.1-2b-it\" #out of memory error\n# DEFAULT_LLM_MODEL = \"tiiuae/falcon-7b-instruct\" #out of memory error\n# LLM for generating answers\n# DEFAULT_LLM_MODEL = \"deepseek-ai/DeepSeek-V3-0324\"                         # LLM for generating answers\n# DEFAULT_LLM_MODEL = \"meta-llama/Meta-Llama-3-8B-Instruct\"\nDEFAULT_LLM_MODEL = \"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\"\n# DEFAULT_DOCUMENT_DIR = \"/data/corpus.zip\"\nDEFAULT_DOCUMENT_DIR = \"/kaggle/input/daa-lectures-for-a4/cmu-lecs\"\n# DEFAULT_DOCUMENT_DIR = \"/content/\"  # Changed to the directory path\n\nDEFAULT_LLM_MODEL","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:09:49.318074Z","iopub.execute_input":"2025-04-19T18:09:49.318280Z","iopub.status.idle":"2025-04-19T18:09:49.323456Z","shell.execute_reply.started":"2025-04-19T18:09:49.318266Z","shell.execute_reply":"2025-04-19T18:09:49.322878Z"},"id":"uvpZHpqdEbwQ"},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"'NousResearch/Nous-Hermes-2-Mistral-7B-DPO'"},"metadata":{}}],"execution_count":29},{"cell_type":"markdown","source":"# Document Processing Functions","metadata":{"id":"L1E1l1iNxLEF"}},{"cell_type":"code","source":"def load_documents(directory: str, glob_pattern: str = \"**/*.pdf\") -> List[Document]:\n    \"\"\"\n    Loads all PDF files from a given directory.\n\n    Args:\n        directory: path to folder with PDF files\n        glob_pattern: pattern to match files (default = all PDFs)\n\n    Returns:\n        List of LangChain Document objects\n    \"\"\"\n    loader = DirectoryLoader(directory, glob=glob_pattern, loader_cls=PyPDFLoader)\n    return loader.load()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.641856Z","iopub.execute_input":"2025-04-19T18:04:29.642041Z","iopub.status.idle":"2025-04-19T18:04:29.654098Z","shell.execute_reply.started":"2025-04-19T18:04:29.642026Z","shell.execute_reply":"2025-04-19T18:04:29.653614Z"},"id":"HV2X-Xd7EbwQ"},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def chunk_documents(\n    documents: List[Document],\n    chunk_size: int = DEFAULT_CHUNK_SIZE,\n    chunk_overlap: int = DEFAULT_CHUNK_OVERLAP,\n    separators: List[str] = None\n) -> List[Document]:\n    \"\"\"\n    Splits documents into chunks for better retrieval.\n\n    Args:\n        documents: list of LangChain documents\n        chunk_size: size of each chunk\n        chunk_overlap: how much content overlaps between chunks\n        separators: optional list of separators for better splitting\n\n    Returns:\n        List of chunked Document objects\n    \"\"\"\n    if separators is None:\n        # Default separators: prioritize splitting on paragraphs, then sentences, then words\n        separators = [\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=chunk_size,\n        chunk_overlap=chunk_overlap,\n        separators=separators\n    )\n    return text_splitter.split_documents(documents)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.656621Z","iopub.execute_input":"2025-04-19T18:04:29.656832Z","iopub.status.idle":"2025-04-19T18:04:29.668130Z","shell.execute_reply.started":"2025-04-19T18:04:29.656817Z","shell.execute_reply":"2025-04-19T18:04:29.667556Z"},"id":"k1ua7tohEbwR"},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def create_vector_store(\n    chunks: List[Document],\n    embedding_model: str = DEFAULT_EMBEDDING_MODEL,\n    save_path: str = None\n) -> FAISS:\n    \"\"\"\n    Creates a FAISS vector index from document chunks using specified embedding model.\n\n    Args:\n        chunks: list of Document chunks\n        embedding_model: HuggingFace model used for embeddings\n        save_path: optional path to save the index\n\n    Returns:\n        FAISS vector store\n    \"\"\"\n    embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n    vectordb = FAISS.from_documents(chunks, embeddings)\n\n    if save_path:\n        vectordb.save_local(save_path)\n\n    return vectordb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.668790Z","iopub.execute_input":"2025-04-19T18:04:29.669014Z","iopub.status.idle":"2025-04-19T18:04:29.686105Z","shell.execute_reply.started":"2025-04-19T18:04:29.668990Z","shell.execute_reply":"2025-04-19T18:04:29.685458Z"},"id":"IYGOIWotEbwR"},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def create_bm25_index(chunks: List[Document]) -> BM25Okapi:\n    \"\"\"\n    Builds a keyword-based index using BM25.\n\n    Args:\n        chunks: list of Document chunks\n\n    Returns:\n        BM25 index\n    \"\"\"\n    texts = [chunk.page_content for chunk in chunks]                  # Get plain text\n    tokenized_texts = [text.split() for text in texts]               # Tokenize by whitespace\n    return BM25Okapi(tokenized_texts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.686724Z","iopub.execute_input":"2025-04-19T18:04:29.686927Z","iopub.status.idle":"2025-04-19T18:04:29.699926Z","shell.execute_reply.started":"2025-04-19T18:04:29.686913Z","shell.execute_reply":"2025-04-19T18:04:29.699307Z"},"id":"1SBM9zbqEbwR"},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"# Search Functions","metadata":{"id":"p-gPSeFBxLEH"}},{"cell_type":"code","source":"def semantic_search(\n    query: str,\n    vectordb: FAISS,\n    k: int = DEFAULT_SEARCH_K,\n    score_threshold: float = None\n) -> List[Tuple[Document, float]]:\n    \"\"\"\n    Perform semantic search using vector similarity from FAISS.\n\n    Args:\n        query: Natural language question\n        vectordb: Vector index (FAISS)\n        k: Number of results to return\n        score_threshold: Filter out low similarity scores (optional)\n\n    Returns:\n        List of (Document, similarity_score) tuples\n    \"\"\"\n    results = vectordb.similarity_search_with_score(query, k=k)\n\n    # Optional thresholding to remove irrelevant results\n    if score_threshold is not None:\n        results = [(doc, score) for doc, score in results if score >= score_threshold]\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.700536Z","iopub.execute_input":"2025-04-19T18:04:29.700923Z","iopub.status.idle":"2025-04-19T18:04:29.714170Z","shell.execute_reply.started":"2025-04-19T18:04:29.700902Z","shell.execute_reply":"2025-04-19T18:04:29.713674Z"},"id":"fE1SDy_nEbwR"},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def keyword_search(\n    query: str,\n    bm25_index: BM25Okapi,\n    chunks: List[Document],\n    k: int = DEFAULT_SEARCH_K,\n    score_threshold: float = None\n) -> List[Tuple[Document, float]]:\n    \"\"\"\n    Perform lexical search using BM25.\n\n    Args:\n        query: Search query string\n        bm25_index: Pre-built BM25 index\n        chunks: List of document chunks for mapping back\n        k: Top-k documents to retrieve\n        score_threshold: Optional filtering threshold for BM25 scores\n\n    Returns:\n        List of (Document, BM25_score) tuples\n    \"\"\"\n    tokenized_query = query.split()  # Basic whitespace tokenization\n    scores = bm25_index.get_scores(tokenized_query)\n\n    # Get indices of top-k documents\n    top_k_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:k]\n\n    results = [(chunks[i], scores[i]) for i in top_k_indices]\n\n    if score_threshold is not None:\n        results = [(doc, score) for doc, score in results if score >= score_threshold]\n\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.714923Z","iopub.execute_input":"2025-04-19T18:04:29.715166Z","iopub.status.idle":"2025-04-19T18:04:29.732447Z","shell.execute_reply.started":"2025-04-19T18:04:29.715145Z","shell.execute_reply":"2025-04-19T18:04:29.731910Z"},"id":"Nhfc2td3EbwS"},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def hybrid_search(\n    query: str,\n    vectordb: FAISS,\n    bm25_index: BM25Okapi,\n    chunks: List[Document],\n    k: int = DEFAULT_SEARCH_K,\n    semantic_weight: float = 0.5,\n    keyword_weight: float = 0.5\n) -> List[Tuple[Document, float]]:\n    \"\"\"\n    Combine semantic and keyword search using weighted score fusion.\n\n    Args:\n        query: Natural language query\n        vectordb: FAISS vector database\n        bm25_index: BM25 keyword index\n        chunks: Document chunks (used for mapping back)\n        k: Top-k results to return\n        semantic_weight: Weight for vector similarity\n        keyword_weight: Weight for BM25 relevance\n\n    Returns:\n        List of (Document, combined_score) tuples\n    \"\"\"\n    # Step 1: Run both types of searches with larger k (to capture wider context)\n    semantic_results = semantic_search(query, vectordb, k * 2)\n    semantic_scores = {doc.page_content: score for doc, score in semantic_results}\n\n    keyword_results = keyword_search(query, bm25_index, chunks, k * 2)\n    keyword_scores = {doc.page_content: score for doc, score in keyword_results}\n\n    # Step 2: Normalize BM25 scores (they are not bounded, unlike cosine similarity)\n    max_kw_score = max(keyword_scores.values()) if keyword_scores else 1\n\n    # Step 3: Combine results\n    all_docs = set(semantic_scores.keys()).union(set(keyword_scores.keys()))\n    combined_scores = []\n\n    for doc_content in all_docs:\n        sem_score = semantic_scores.get(doc_content, 0)\n        kw_score = keyword_scores.get(doc_content, 0)\n        norm_kw_score = kw_score / max_kw_score if max_kw_score > 0 else 0\n\n        # Weighted sum of both types of scores\n        combined_score = (semantic_weight * sem_score) + (keyword_weight * norm_kw_score)\n        combined_scores.append((doc_content, combined_score))\n\n    # Step 4: Sort and return top-k\n    combined_scores.sort(key=lambda x: x[1], reverse=True)\n    top_scores = combined_scores[:k]\n\n    # Step 5: Re-map back to full Document objects using content\n    doc_lookup = {chunk.page_content: chunk for chunk in chunks}\n    results = []\n\n    for doc_content, score in top_scores:\n        if doc_content in doc_lookup:\n            results.append((doc_lookup[doc_content], score))\n\n    return results","metadata":{"execution":{"iopub.status.busy":"2025-04-19T18:04:29.733196Z","iopub.execute_input":"2025-04-19T18:04:29.733417Z","iopub.status.idle":"2025-04-19T18:04:29.748616Z","shell.execute_reply.started":"2025-04-19T18:04:29.733403Z","shell.execute_reply":"2025-04-19T18:04:29.747973Z"},"id":"J3T0XMX0xLEH","trusted":true},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"# LLM functions","metadata":{"id":"7Q5NGOdUxLEI"}},{"cell_type":"code","source":"def initialize_llm(\n    model_name: str = DEFAULT_LLM_MODEL,\n    device: str = \"cuda\",  # Use \"cpu\" if not using GPU\n    max_new_tokens: int = 300\n) -> Tuple[pipeline, any]:\n    \"\"\"\n    Loads a language model pipeline for text generation.\n\n    Args:\n        model_name: HuggingFace model repo (must support causal LM)\n        device: \"cuda\" for GPU or \"cpu\"\n        max_new_tokens: Max tokens to generate per response\n\n    Returns:\n        Tuple (generator pipeline, tokenizer)\n    \"\"\"\n    try:\n        model = AutoModelForCausalLM.from_pretrained(\n            model_name,\n            device_map=device,\n            torch_dtype=\"auto\",            # Uses GPU acceleration if available\n            trust_remote_code=True         # Allow custom model architectures\n        )\n        print(\"Original used\")\n    except ImportError:\n        # Fallback without device_map\n        model = AutoModelForCausalLM.from_pretrained(\n            model_name,\n            torch_dtype=\"auto\",\n            trust_remote_code=True\n        ).to(device)\n        print(\"Edited used\")\n\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n    # Format the prompt as a dialogue (user + assistant style)\n    tokenizer.chat_template = (\n        \"{% for message in messages %}\"\n        \"{% if message['role'] == 'user' %}User: {{ message['content'] }}\\n\"\n        \"{% elif message['role'] == 'assistant' %}Assistant: {{ message['content'] }}\\n\"\n        \"{% endif %}\"\n        \"{% endfor %}\"\n        \"{% if add_generation_prompt %}Assistant:{% endif %}\"\n    )\n\n    # Create a text-generation pipeline\n    generator = pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        return_full_text=False,        # Only return generated part, not the full prompt\n        max_new_tokens=max_new_tokens,\n        do_sample=True                 # Use sampling (stochastic generation)\n    )\n\n    return generator, tokenizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.749279Z","iopub.execute_input":"2025-04-19T18:04:29.749433Z","iopub.status.idle":"2025-04-19T18:04:29.765566Z","shell.execute_reply.started":"2025-04-19T18:04:29.749420Z","shell.execute_reply":"2025-04-19T18:04:29.764941Z"},"id":"v89jLCD_EbwS"},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def generate_response(\n    prompt: str,\n    generator: pipeline,\n    width: int = 80  # For pretty-printing long outputs\n) -> str:\n    \"\"\"\n    Generates a response from the LLM using the prompt.\n\n    Args:\n        prompt: Full RAG-formatted prompt with question + context\n        generator: HF pipeline object\n        width: max characters per printed line (for wrapping)\n\n    Returns:\n        Answer string\n    \"\"\"\n    messages = [{\"role\": \"user\", \"content\": prompt}]        # Wrap prompt in chat message format\n    output = generator(\n        messages,\n        max_new_tokens=256,\n        temperature=0.7,\n        top_p=0.9,\n        do_sample=True\n    )\n                            # Call LLM\n    return textwrap.fill(output[0][\"generated_text\"], width=width)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.766300Z","iopub.execute_input":"2025-04-19T18:04:29.767000Z","iopub.status.idle":"2025-04-19T18:04:29.783290Z","shell.execute_reply.started":"2025-04-19T18:04:29.766977Z","shell.execute_reply":"2025-04-19T18:04:29.782687Z"},"id":"kQMhtE8lEbwT"},"outputs":[],"execution_count":20},{"cell_type":"code","source":"def format_rag_prompt(\n    question: str,\n    retrieved_docs: List[Document],\n    instruction: str = None\n) -> str:\n    \"\"\"\n    Formats the final input prompt to send to the LLM.\n\n    Args:\n        question: The user's natural language question\n        retrieved_docs: List of document chunks retrieved by search\n        instruction: Optional prompt instructions (system message)\n\n    Returns:\n        Full prompt text string\n    \"\"\"\n    # Default instructions to guide the LLM on how to use retrieved documents\n    if instruction is None:\n        instruction = \"\"\"You are an AI assistant tasked with answering questions based on retrieved knowledge.\n                    - Integrate the key points from all retrieved responses into a cohesive, well-structured answer.\n                    - If the responses are contradictory, mention the different perspectives.\n                    - If none of the retrieved responses contain relevant information, reply:\n                    \"I couldn't find a good response to your query in the database.\"\n                    \"\"\"\n\n    # Truncate each document to 1000 characters if long\n    retrieved_info = \"\\n\\n\".join(\n        f\"{i+1}️⃣ {doc.page_content[:1000]}...\" if len(doc.page_content) > 1000\n        else f\"{i+1}️⃣ {doc.page_content}\"\n        for i, doc in enumerate(retrieved_docs)\n    )\n\n    # Final structured prompt\n    return f\"\"\"\n        {instruction}\n\n        ### Retrieved Information:\n        {retrieved_info}\n\n        ### Question:\n        {question}\n    \"\"\"","metadata":{"execution":{"iopub.status.busy":"2025-04-19T18:04:29.783863Z","iopub.execute_input":"2025-04-19T18:04:29.784041Z","iopub.status.idle":"2025-04-19T18:04:29.800488Z","shell.execute_reply.started":"2025-04-19T18:04:29.784027Z","shell.execute_reply":"2025-04-19T18:04:29.799972Z"},"id":"9GJIwleTxLEJ","trusted":true},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":"# RAG Evaluator","metadata":{"id":"07jDDqiSxLEJ"}},{"cell_type":"code","source":"# WRAPPER TO USE LANGCHAIN LLM IN RAGAS\n\nclass HuggingFaceLLMWrapper:\n    \"\"\"\n    Wrapper for using HuggingFacePipeline with RAGAS evaluation.\n    Includes a dummy 'set_run_config' to avoid errors.\n    \"\"\"\n\n    def __init__(self, pipeline):\n        self.pipeline = pipeline\n\n    def __call__(self, prompt: str) -> str:\n        return self.pipeline(prompt)\n\n    def set_run_config(self, run_config):\n        \"\"\"Dummy method to avoid errors with ragas.\"\"\"\n        pass  # Do nothing, as TextGenerationPipeline doesn't have this method","metadata":{"id":"86nm904ENFqi","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.801037Z","iopub.execute_input":"2025-04-19T18:04:29.801187Z","iopub.status.idle":"2025-04-19T18:04:29.816784Z","shell.execute_reply.started":"2025-04-19T18:04:29.801176Z","shell.execute_reply":"2025-04-19T18:04:29.816092Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# WRAPPER TO USE LANGCHAIN LLM IN RAGAS\n\nclass HuggingFaceLLM:\n    \"\"\"\n    Simple wrapper for using HuggingFaceHub with RAGAS evaluation.\n    \"\"\"\n    def __init__(self, model_name: str):\n        self.model = HuggingFaceHub(repo_id=model_name)\n\n    def __call__(self, prompt: str) -> str:\n        return self.model(prompt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.817435Z","iopub.execute_input":"2025-04-19T18:04:29.817624Z","iopub.status.idle":"2025-04-19T18:04:29.833740Z","shell.execute_reply.started":"2025-04-19T18:04:29.817610Z","shell.execute_reply":"2025-04-19T18:04:29.833201Z"},"id":"eKsmE4PVEbwU"},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# EVALUATOR CLASS\n\nclass RAGEvaluator:\n    \"\"\"\n    Performs automatic evaluation of RAG responses using Ragas metrics.\n    Also supports result visualization and optimization insights.\n    \"\"\"\n    def __init__(self, pipeline, llm, embeddings):\n        self.pipeline = pipeline         # RAGPipeline object\n        self.embeddings = embeddings     # HuggingFaceEmbeddings instance\n\n        # Use passed LLM, or initialize default\n        if isinstance(llm, str):\n            self.llm = HuggingFaceHub(repo_id=llm)\n        else:\n            self.llm = HuggingFaceLLMWrapper(llm) if llm else HuggingFaceLLMWrapper(HuggingFaceHub(repo_id=DEFAULT_LLM_MODEL))\n\n        # Internal result tracking\n        self.results = []\n\n    def evaluate_ragas(self, questions: list, gold_answers: list = None):\n        \"\"\"\n        Run Ragas evaluation across all questions.\n\n        Args:\n            questions: List of input questions\n            gold_answers: Reference answers (optional)\n\n        Returns:\n            DataFrame of results\n        \"\"\"\n        all_rows = []\n\n        for question, gold_answer in zip(questions, gold_answers or [None]*len(questions)):\n            # Run full RAG query\n            answer = self.pipeline.query(question)\n\n            # Get context used in the answer\n            contexts = [doc.page_content for doc in self.pipeline.get_last_retrieved_docs()]\n\n            # Prepare a single sample for evaluation\n            data = {\n                \"question\": [question],\n                \"answer\": [answer],\n                \"contexts\": [contexts]\n            }\n            if gold_answer:\n                data[\"ground_truth\"] = [gold_answer]\n\n            dataset = Dataset.from_dict(data)\n\n            # Select metrics to compute\n            metrics = [Faithfulness(), AnswerRelevancy(), ContextRecall(), ContextPrecision()]\n            if gold_answer:\n                metrics.append(AnswerCorrectness())\n\n            # Run the evaluation\n            result = evaluate(dataset, metrics=metrics, llm=self.llm, embeddings=self.embeddings)\n\n            # Convert to DataFrame and store\n            row = result.to_pandas()\n            row[\"question\"] = question\n            row[\"retrieved_docs\"] = len(contexts)\n            all_rows.append(row)\n\n        # Combine all rows into one DataFrame\n        self.results = pd.concat(all_rows, ignore_index=True)\n        return self.results\n\n    def visualize_metrics(self):\n        \"\"\"\n        Visualize average metric scores and context retrieval stats.\n        \"\"\"\n        if self.results is None or self.results.empty:\n            raise ValueError(\"No evaluation results found. Run evaluate_ragas() first.\")\n\n        # Plot main metrics\n        metrics = ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision']\n        if 'answer_correctness' in self.results.columns:\n            metrics.append('answer_correctness')\n\n        plt.figure(figsize=(10, 5))\n        self.results[metrics].mean().plot(kind='bar', color='lightblue')\n        plt.title(\"🔍 Average RAG Evaluation Metrics\")\n        plt.ylabel(\"Score (0 to 1)\")\n        plt.xticks(rotation=45)\n        plt.grid(axis='y', linestyle='--', alpha=0.5)\n        plt.show()\n\n        # Plot document retrieval counts\n        plt.figure(figsize=(8, 4))\n        self.results['retrieved_docs'].value_counts().sort_index().plot(kind='bar', color='lightgreen')\n        plt.title(\"📄 Number of Context Chunks Retrieved Per Query\")\n        plt.xlabel(\"Number of Chunks\")\n        plt.ylabel(\"Frequency\")\n        plt.grid(axis='y', linestyle='--', alpha=0.5)\n        plt.show()\n\n    def get_optimization_insights(self):\n        \"\"\"\n        Analyze weak metrics and recommend strategies to improve RAG performance.\n        \"\"\"\n        if self.results is None or self.results.empty:\n            return \"No evaluation results available.\"\n\n        insights = []\n        df = self.results\n\n        # Faithfulness issues (hallucination)\n        if df['faithfulness'].mean() < 0.7:\n            insights.append(\"⚠️ Faithfulness is low — possible hallucinations.\")\n            insights.append(\"🔧 Try increasing chunk overlap or improving retrieval relevance.\")\n\n        # Context recall issues (missing info)\n        if df['context_recall'].mean() < 0.6:\n            insights.append(\"⚠️ Low context recall — relevant info may be missed.\")\n            insights.append(\"🔧 Consider using hybrid retrieval or adjusting chunk size.\")\n\n        # Precision issues (irrelevant info)\n        if df['context_precision'].mean() < 0.6:\n            insights.append(\"⚠️ Low context precision — too much irrelevant context.\")\n            insights.append(\"🔧 Use better embeddings or rerank retrieved chunks.\")\n\n        # Relevance issues (answer not matching question)\n        if df['answer_relevancy'].mean() < 0.7:\n            insights.append(\"⚠️ Low answer relevancy — answers not matching question.\")\n            insights.append(\"🔧 Refine your prompts or improve chunk matching.\")\n\n        # Optional: Correctness based on gold answers\n        if 'answer_correctness' in df.columns and df['answer_correctness'].mean() < 0.7:\n            insights.append(\"⚠️ Low correctness — answers differ from references.\")\n            insights.append(\"🔧 Try different LLMs or use post-editing.\")\n\n        return \"\\n\".join(insights)","metadata":{"id":"DAFXSDHQxLEK","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.834417Z","iopub.execute_input":"2025-04-19T18:04:29.834740Z","iopub.status.idle":"2025-04-19T18:04:29.854762Z","shell.execute_reply.started":"2025-04-19T18:04:29.834718Z","shell.execute_reply":"2025-04-19T18:04:29.854059Z"}},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":"# RAG Pipeline","metadata":{"id":"r1Lfz6KJxLEL"}},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer, util\nimport numpy as np\n\nclass SimpleEvaluator:\n    \"\"\"\n    Evaluates the quality of generated answers by comparing the original question\n    with a regenerated question from the generated answer.\n    \"\"\"\n    def __init__(self, llm, tokenizer, embedding_model: str = DEFAULT_EMBEDDING_MODEL):\n        self.llm = llm\n        self.tokenizer = tokenizer\n        self.embedding_model = SentenceTransformer(embedding_model)\n\n    def generate_question(self, answer: str, max_chars: int = 200) -> str:\n        \"\"\"\n        Generates a single-sentence question from a given answer.\n    \n        Args:\n            answer: The answer text to reverse-generate a question for.\n            max_chars: Maximum character length of the output question.\n    \n        Returns:\n            A short, single question string.\n        \"\"\"\n        prompt = (\n            \"You are a question generation AI.\\n\"\n            \"Generate exactly one concise, clear question (no explanations) that can be answered using the following passage.\\n\\n\"\n            f\"PASSAGE:\\n{answer}\\n\\n\"\n            \"QUESTION (one line only):\"\n        )\n    \n        messages = [{\"role\": \"user\", \"content\": prompt}]\n        output = self.llm(\n            messages,\n            max_new_tokens=64,          # prevent long rambly generations\n            temperature=0.7,\n            do_sample=True,\n            top_p=0.9\n        )\n    \n        # Get the first sentence and truncate if necessary\n        full_output = output[0][\"generated_text\"].strip()\n        single_line = full_output.split(\"\\n\")[0].strip()  # grab first line\n        trimmed = single_line[:max_chars].strip()\n    \n        # Ensure it ends with a question mark\n        if not trimmed.endswith(\"?\"):\n            trimmed += \"?\"\n    \n        return trimmed\n\n    def compute_faithfulness(self, generated_answer: str, retrieved_docs: list) -> float:\n        \"\"\"\n        Computes faithfulness score between answer and retrieved docs.\n        \"\"\"\n        combined_context = \" \".join([doc.page_content for doc in retrieved_docs])\n        emb_ans = self.embedding_model.encode(generated_answer, convert_to_tensor=True)\n        emb_ctx = self.embedding_model.encode(combined_context, convert_to_tensor=True)\n        return float(util.pytorch_cos_sim(emb_ans, emb_ctx).item())\n\n    def compute_similarity(self, q1: str, q2: str) -> float:\n        emb1 = self.embedding_model.encode(q1, convert_to_tensor=True)\n        emb2 = self.embedding_model.encode(q2, convert_to_tensor=True)\n        return float(util.pytorch_cos_sim(emb1, emb2).item())\n\n    def evaluate(self, question: str, generated_answer: str, retrieved_docs: list) -> dict:\n        regenerated_q = self.generate_question(generated_answer)\n        q_similarity = self.compute_similarity(question, regenerated_q)\n        faith_score = self.compute_faithfulness(generated_answer, retrieved_docs)\n        return {\n            \"original_question\": question,\n            \"regenerated_question\": regenerated_q,\n            \"question_similarity\": round(q_similarity, 4),\n            \"faithfulness_score\": round(faith_score, 4)\n        }\n","metadata":{"id":"70ftZAKCSjyr","trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:04:29.855473Z","iopub.execute_input":"2025-04-19T18:04:29.855736Z","iopub.status.idle":"2025-04-19T18:04:31.509044Z","shell.execute_reply.started":"2025-04-19T18:04:29.855715Z","shell.execute_reply":"2025-04-19T18:04:31.508236Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# MAIN RAG PIPELINE\n\nclass RAGPipeline:\n    \"\"\"\n    This is the central class that handles:\n    - Loading and chunking documents\n    - Initializing vector and keyword search\n    - Running queries\n    - Generating responses from the LLM\n    - Running full experiment sweeps\n    \"\"\"\n    def __init__(\n        self,\n        document_dir: str,\n        embedding_model: str = DEFAULT_EMBEDDING_MODEL,\n        llm_model: str = DEFAULT_LLM_MODEL,\n        chunk_size: int = DEFAULT_CHUNK_SIZE,\n        chunk_overlap: int = DEFAULT_CHUNK_OVERLAP,\n        device: str = \"cuda\"\n    ):\n        self.document_dir = document_dir\n        self.embedding_model = embedding_model\n        self.llm_model = llm_model\n        self.chunk_size = chunk_size\n        self.chunk_overlap = chunk_overlap\n        self.device = device\n\n        # To store runtime state\n        self.documents = None\n        self.chunks = None\n        self.vectordb = None\n        self.bm25_index = None\n        self.llm = None\n        self.tokenizer = None\n        self.last_retrieved_docs = None  # For evaluation traceability\n\n\n    # ==========================\n    # LOAD & CHUNK DOCUMENTS\n    # ==========================\n    def load_and_process_documents(self):\n        \"\"\"\n        Loads PDF documents and splits them into overlapping chunks.\n        \"\"\"\n        print(\"📄 Loading documents...\")\n        self.documents = load_documents(self.document_dir)\n        print(f\"✅ Loaded {len(self.documents)} document pages.\")\n\n        print(\"🪓 Chunking documents...\")\n        self.chunks = chunk_documents(\n            self.documents,\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap\n        )\n        print(f\"✅ Created {len(self.chunks)} chunks.\")\n\n        # Add unique IDs to chunks for tracking\n        for i, chunk in enumerate(self.chunks):\n            chunk.metadata[\"chunk_id\"] = i\n\n\n    # ==========================\n    # INITIALIZE RETRIEVAL\n    # ==========================\n    def initialize_retrieval(self):\n        \"\"\"\n        Builds vector store and keyword index for retrieval.\n        \"\"\"\n        if not self.chunks:\n            raise ValueError(\"❌ No chunks found. Run load_and_process_documents() first.\")\n\n        print(\"📦 Creating vector store...\")\n        self.vectordb = create_vector_store(self.chunks, self.embedding_model)\n\n        print(\"🔎 Creating BM25 index...\")\n        self.bm25_index = create_bm25_index(self.chunks)\n\n\n    # ==========================\n    # INITIALIZE LLM\n    # ==========================\n    def initialize_llm(self):\n        \"\"\"\n        Loads the chosen LLM and tokenizer from HuggingFace.\n        \"\"\"\n        print(\"🤖 Loading LLM...\")\n        self.llm, self.tokenizer = initialize_llm(self.llm_model, self.device)\n\n\n    # ==========================\n    # GET LAST RETRIEVED CHUNKS\n    # ==========================\n    def get_last_retrieved_docs(self):\n        \"\"\"\n        Returns the last set of retrieved document chunks (used in evaluation).\n        \"\"\"\n        if self.last_retrieved_docs is None:\n            raise ValueError(\"❌ No retrievals done yet.\")\n        return self.last_retrieved_docs\n\n\n    # ==========================\n    # MAIN QUERY FUNCTION\n    # ==========================\n    def query(\n        self,\n        question: str,\n        search_type: str = DEFAULT_SEARCH_TYPE,  # semantic / keyword / hybrid\n        k: int = DEFAULT_SEARCH_K,\n        semantic_weight: float = 0.5,\n        keyword_weight: float = 0.5,\n        custom_instruction: str = None\n    ) -> str:\n        \"\"\"\n        Executes a full query through the pipeline:\n        - Retrieves chunks\n        - Formats prompt\n        - Calls LLM\n        - Returns answer\n        \"\"\"\n        if not self.vectordb or not self.bm25_index:\n            raise ValueError(\"❌ Retrieval systems not ready. Run initialize_retrieval().\")\n        if not self.llm:\n            raise ValueError(\"❌ LLM not initialized. Run initialize_llm().\")\n\n        # Step 1: Retrieve relevant documents\n        if search_type == \"semantic\":\n            results = semantic_search(question, self.vectordb, k)\n        elif search_type == \"keyword\":\n            results = keyword_search(question, self.bm25_index, self.chunks, k)\n        elif search_type == \"hybrid\":\n            results = hybrid_search(\n                question,\n                self.vectordb,\n                self.bm25_index,\n                self.chunks,\n                k,\n                semantic_weight,\n                keyword_weight\n            )\n        else:\n            raise ValueError(f\"❌ Unknown search type: {search_type}\")\n\n        retrieved_docs = [doc for doc, _ in results]\n        self.last_retrieved_docs = retrieved_docs\n\n        # Step 2: Format prompt\n        prompt = format_rag_prompt(question, retrieved_docs, custom_instruction)\n\n        # Step 3: Generate LLM response\n        return generate_response(prompt, self.llm)\n\n\n    # ==========================\n    # EXPERIMENTATION FUNCTION\n    # ==========================\n    def experiment(\n        self,\n        questions: List[str],\n        gold_answers: List[str],\n        chunk_sizes: List[int],\n        k_values: List[int],\n        search_types: List[str],\n        chunk_overlaps: List[int] = [0, 100, 200]\n    ) -> Dict:\n        \"\"\"\n        Run multiple experiment configurations (varying chunk size, k, search type).\n\n        Args:\n            questions: list of input queries\n            gold_answers: reference answers (used in evaluation)\n            chunk_sizes: different chunk sizes to test\n            k_values: number of results to retrieve\n            search_types: list of retrieval modes\n            chunk_overlaps: amount of content overlap between chunks\n\n        Returns:\n            A dict of results by config\n        \"\"\"\n        results = {}\n\n        for chunk_size in chunk_sizes:\n            for chunk_overlap in chunk_overlaps:\n                self.chunk_size = chunk_size\n                self.chunk_overlap = chunk_overlap\n\n                print(f\"\\n⚙️  Testing: chunk={chunk_size}, overlap={chunk_overlap}\")\n                self.load_and_process_documents()\n                self.initialize_retrieval()\n\n                evaluator = RAGEvaluator(self, self.llm, HuggingFaceEmbeddings(model_name=self.embedding_model))\n\n                for search_type in search_types:\n                    for k in k_values:\n                        config_name = f\"chunk{chunk_size}_overlap{chunk_overlap}_{search_type}_k{k}\"\n                        results[config_name] = {}\n\n                        for question in questions:\n                            try:\n                                answer = self.query(\n                                    question,\n                                    search_type=search_type,\n                                    k=k\n                                )\n                                results[config_name][question] = answer\n\n                                # Run evaluation (with gold answer)\n                                eval_result = evaluator.evaluate_ragas([question], [gold_answers[0]])\n                                print(eval_result[['faithfulness', 'answer_relevancy']])\n\n                                # Visualization + optimization\n                                evaluator.visualize_metrics()\n                                print(\"\\n🧠 Optimization Suggestions:\")\n                                print(evaluator.get_optimization_insights())\n\n                            except Exception as e:\n                                results[config_name][question] = f\"❌ Error: {str(e)}\"\n\n        return results\n\n\n    def grid_search(\n        self,\n        questions: List[str],\n        gold_answers: List[str],\n        chunk_sizes: List[int],\n        k_values: List[int],\n        search_types: List[str],\n        chunk_overlaps: List[int] = [0, 100, 200],\n        semantic_weight: float = 0.5,\n        keyword_weight: float = 0.5,\n        output_csv_path: str = \"rag_grid_search_results.csv\"\n    ) -> Dict:\n        \"\"\"\n        Run grid search over multiple config combinations and log results to CSV.\n\n        Returns:\n            Dictionary of results.\n        \"\"\"\n        results = []\n        header_written = False\n\n        # Ensure output directory exists\n        os.makedirs(os.path.dirname(output_csv_path) or \".\", exist_ok=True)\n\n        with open(output_csv_path, mode='w', newline='', encoding='utf-8') as file:\n            writer = csv.writer(file)\n\n            for chunk_size in chunk_sizes:\n                for chunk_overlap in chunk_overlaps:\n                    if chunk_overlap >= chunk_size:\n                        continue\n                    self.chunk_size = chunk_size\n                    self.chunk_overlap = chunk_overlap\n\n                    self.load_and_process_documents()\n                    self.initialize_retrieval()\n\n                    evaluator = SimpleEvaluator(self.llm, self.tokenizer)\n\n                    for search_type in search_types:\n                        for k in k_values:\n                            config_name = f\"chunk{chunk_size}_overlap{chunk_overlap}_{search_type}_k{k}\"\n                            print(f\"\\n🔬 Running Config: {config_name}\")\n\n                            for i, question in enumerate(questions):\n                                try:\n                                    start_time = time.time()\n\n                                    # Step 1: Query\n                                    retrieval_start = time.time()\n                                    answer = self.query(\n                                        question=question,\n                                        search_type=search_type,\n                                        k=k,\n                                        semantic_weight=semantic_weight,\n                                        keyword_weight=keyword_weight\n                                    )\n                                    retrieval_end = time.time()\n\n                                    # Step 2: Evaluation\n                                    eval_df = evaluator.evaluate([question], [answer], self.last_retrieved_docs)\n                                    # eval_row = eval_df.iloc[0].to_dict()\n\n                                    # Step 3: Timing\n                                    end_time = time.time()\n                                    total_time = end_time - start_time\n                                    retrieval_time = retrieval_end - retrieval_start\n                                    generation_time = total_time - retrieval_time\n\n                                    print(eval_df)\n\n                                    # # Visualization + optimization\n                                    # evaluator.visualize_metrics()\n                                    # print(\"\\n🧠 Optimization Suggestions:\")\n                                    # print(evaluator.get_optimization_insights())\n\n                                    # Step 4: Build result row\n                                    row = {\n                                        \"time run\":  print_date_time(),\n                                        \"config\": config_name,\n                                        \"question\": question,\n                                        \"answer\": answer,\n                                        \"retrieved_documents\": self.last_retrieved_docs,\n                                        \"chunk_size\": chunk_size,\n                                        \"chunk_overlap\": chunk_overlap,\n                                        \"search_type\": search_type,\n                                        \"top_k\": k,\n                                        \"semantic_weight\": semantic_weight,\n                                        \"keyword_weight\": keyword_weight,\n                                        \"LLM\": self.llm_model,\n                                        \"embedding_model\": self.embedding_model,\n                                        \"retrieval_time\": round(retrieval_time, 4),\n                                        \"generation_time\": round(generation_time, 4),\n                                        \"total_time\": round(total_time, 4),\n                                        **eval_df\n                                    }\n\n                                    # Write CSV header if needed\n                                    if not header_written:\n                                        writer.writerow(row.keys())\n                                        header_written = True\n\n                                    writer.writerow(row.values())\n                                    results.append(row)\n\n                                except Exception as e:\n                                    print(f\"⚠️ Error in config {config_name} for question '{question}': {e}\")\n                                    writer.writerow([config_name, question, f\"Error: {str(e)}\"])\n\n        print(f\"\\n✅ All results logged to: {output_csv_path}\")\n        return results","metadata":{"execution":{"iopub.status.busy":"2025-04-19T18:04:31.510200Z","iopub.execute_input":"2025-04-19T18:04:31.510545Z","iopub.status.idle":"2025-04-19T18:04:31.556421Z","shell.execute_reply.started":"2025-04-19T18:04:31.510517Z","shell.execute_reply":"2025-04-19T18:04:31.555706Z"},"id":"ebUXkzJ5xLEL","trusted":true},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# Running\nhere we now run the code","metadata":{"id":"ieAPdGVSEbwW"}},{"cell_type":"code","source":"# STEP 1: CREATE EMBEDDINGS & LLM WRAPPER\n\n# Use the same model you defined as DEFAULT_EMBEDDING_MODEL\nembeddings = HuggingFaceEmbeddings(model_name=DEFAULT_EMBEDDING_MODEL)\n\n# Initialize LLM pipeline\ngenerator, tokenizer = initialize_llm(\n    model_name=DEFAULT_LLM_MODEL,     # <-- Use the same LLM constant from above\n    device=\"cuda\",                    # \"cuda\" or \"cpu\"\n    max_new_tokens=500                # <-- You can increase this if responses are too short\n)\n\n# Wrap your generator for LangChain compatibility\nlocal_llm = HuggingFacePipeline(pipeline=generator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:10:14.924402Z","iopub.execute_input":"2025-04-19T18:10:14.924989Z","iopub.status.idle":"2025-04-19T18:11:21.296816Z","shell.execute_reply.started":"2025-04-19T18:10:14.924965Z","shell.execute_reply":"2025-04-19T18:11:21.296072Z"},"id":"C97jGDKVEbwX","outputId":"35c9a6e3-abe3-4a5d-e39d-040b6cb38b0b","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c0f26a18fac40b8b9be1f8d613853ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe2df1134c15411996785ca0e5540bc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 3 files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e5cec632b3240aaa19459f0e42d71cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4ffe91f5cf24d7d9c53a59ac6cb1163"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9ce57f1d9e94d3681c28664979f62f1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c6c5185579640d58d0dd3e0339481c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"037b2b8691a64c918f9fa9807bde2e9d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/120 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"721e36bcb61547d08e5ba4d0088561ea"}},"metadata":{}},{"name":"stdout","text":"Original used\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.65k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"853ef5f3c6c9487e90f3f4dbb4d7d2bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afb4c599461443d78ff4e80fdf986ec1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/51.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02dc8de26d2f4eabaf9e7fa52c52e478"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/443 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1130040f9d3041c78ca378fd3608a8cf"}},"metadata":{}},{"name":"stderr","text":"Device set to use cuda\n/tmp/ipykernel_31/6713295.py:14: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n  local_llm = HuggingFacePipeline(pipeline=generator)\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"# STEP 2: INITIALIZE RAG PIPELINE\n\nrag = RAGPipeline(\n    document_dir=DEFAULT_DOCUMENT_DIR,       # <-- uses constant\n    embedding_model=DEFAULT_EMBEDDING_MODEL,\n    llm_model=DEFAULT_LLM_MODEL,\n    chunk_size=DEFAULT_CHUNK_SIZE,\n    chunk_overlap=DEFAULT_CHUNK_OVERLAP,\n    device=\"cuda\"\n)\nrag","metadata":{"execution":{"iopub.status.busy":"2025-04-19T18:11:21.297979Z","iopub.execute_input":"2025-04-19T18:11:21.298213Z","iopub.status.idle":"2025-04-19T18:11:21.303320Z","shell.execute_reply.started":"2025-04-19T18:11:21.298196Z","shell.execute_reply":"2025-04-19T18:11:21.302656Z"},"id":"oZT87eroxLEM","trusted":true,"outputId":"3d0fba0d-c829-417d-fc96-0bed0f599dde","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"<__main__.RAGPipeline at 0x7da83d605b10>"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"# STEP 3: LOAD DOCUMENTS & PREPARE SYSTEM\n\nrag.load_and_process_documents()\nrag.initialize_retrieval()\nrag.initialize_llm()  # This will use Llama model defined above","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:11:21.304133Z","iopub.execute_input":"2025-04-19T18:11:21.304342Z","iopub.status.idle":"2025-04-19T18:11:34.168894Z","shell.execute_reply.started":"2025-04-19T18:11:21.304328Z","shell.execute_reply":"2025-04-19T18:11:34.167182Z"},"id":"Z6PZiqMbEbwe","outputId":"b44a957e-47d9-4b0c-e07b-dddf3a9e64d5","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"name":"stdout","text":"📄 Loading documents...\n✅ Loaded 101 document pages.\n🪓 Chunking documents...\n✅ Created 256 chunks.\n📦 Creating vector store...\n🔎 Creating BM25 index...\n🤖 Loading LLM...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88f766485fbe42c09b4b439a0e9be863"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/3508604955.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_process_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_retrieval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# This will use Llama model defined above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_31/1943814555.py\u001b[0m in \u001b[0;36minitialize_llm\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \"\"\"\n\u001b[1;32m     86\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🤖 Loading LLM...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitialize_llm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/1037299129.py\u001b[0m in \u001b[0;36minitialize_llm\u001b[0;34m(model_name, device, max_new_tokens)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \"\"\"\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_configs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_config\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m                 \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    572\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4397\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4398\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4399\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4400\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4401\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   4831\u001b[0m             \u001b[0;31m# Skip it with fsdp on ranks other than 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_fsdp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_local_dist_rank_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_quantized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4833\u001b[0;31m                 disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n\u001b[0m\u001b[1;32m   4834\u001b[0m                     \u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4835\u001b[0m                     \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0mparam_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_local_dist_rank_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"meta\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0m_load_parameter_into_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 87.12 MiB is free. Process 3657 has 15.80 GiB memory in use. Of the allocated memory 15.43 GiB is allocated by PyTorch, and 89.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"],"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 15.89 GiB of which 87.12 MiB is free. Process 3657 has 15.80 GiB memory in use. Of the allocated memory 15.43 GiB is allocated by PyTorch, and 89.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error"}],"execution_count":32},{"cell_type":"code","source":"# STEP 4: ASK A SINGLE QUESTION\n\nquestions = [\n    \"What is Dynamic Programming?\"\n    # \"Explain the matrix method in hashing\",\n    # \"What are the key concepts in amortized analysis?\"\n]\n\n# Run query with hybrid search and show result\nanswer = rag.query(\n    questions[0],\n    search_type=DEFAULT_SEARCH_TYPE,\n    k=DEFAULT_SEARCH_K\n)\nprint(f\"\\n🧠 Answer:\\n{answer}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:12:48.896222Z","iopub.execute_input":"2025-04-19T18:12:48.896804Z","iopub.status.idle":"2025-04-19T18:12:48.931520Z","shell.execute_reply.started":"2025-04-19T18:12:48.896779Z","shell.execute_reply":"2025-04-19T18:12:48.930690Z"},"id":"vUgUZ4ArEbwf","outputId":"d3370362-203e-4948-a12d-36bb144135b4","colab":{"base_uri":"https://localhost:8080/","height":517}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/2401295521.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Run query with hybrid search and show result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m answer = rag.query(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mquestions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msearch_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_SEARCH_TYPE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/1943814555.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, question, search_type, k, semantic_weight, keyword_weight, custom_instruction)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"❌ Retrieval systems not ready. Run initialize_retrieval().\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"❌ LLM not initialized. Run initialize_llm().\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Step 1: Retrieve relevant documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: ❌ LLM not initialized. Run initialize_llm()."],"ename":"ValueError","evalue":"❌ LLM not initialized. Run initialize_llm().","output_type":"error"}],"execution_count":34},{"cell_type":"code","source":"# STEP 5: PROVIDE GROUND TRUTH FOR EVALUATION (OPTIONAL)\n\ngold_answers = [\n    \"Dynamic Programming is a technique for solving problems by breaking them into overlapping subproblems, storing intermediate results, and combining them to solve the larger problem efficiently.\"\n    # \"Dynamic Programming is a powerful technique that can be used to solve many combinatorial problems in polynomial time for which a naive approach would take exponential time. Dynamic Programming is a general approach to solving problems, much like “divide-and-conquer”, except that the subproblems will overlap.\"\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:14:09.896191Z","iopub.execute_input":"2025-04-19T18:14:09.896927Z","iopub.status.idle":"2025-04-19T18:14:09.900266Z","shell.execute_reply.started":"2025-04-19T18:14:09.896901Z","shell.execute_reply":"2025-04-19T18:14:09.899528Z"},"id":"aaNOBSlnEbwf"},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# STEP 6: RUN AUTOMATIC EVALUATION\n\nevaluator = RAGEvaluator(rag, llm=local_llm, embeddings=embeddings)\nresults_df = evaluator.evaluate_ragas(questions, gold_answers)\nprint(\"\\n📊 Evaluation Results:\\n\", results_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:11:34.171889Z","iopub.status.idle":"2025-04-19T18:11:34.172196Z","shell.execute_reply.started":"2025-04-19T18:11:34.172043Z","shell.execute_reply":"2025-04-19T18:11:34.172058Z"},"id":"fr32Ich5Ebwf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize performance\nevaluator.visualize_metrics()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:11:34.173066Z","iopub.status.idle":"2025-04-19T18:11:34.173351Z","shell.execute_reply.started":"2025-04-19T18:11:34.173181Z","shell.execute_reply":"2025-04-19T18:11:34.173196Z"},"id":"25CFCtoEEbwf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Show optimization tips\nprint(\"\\n🛠️ Suggestions to Improve RAG System:\")\nprint(evaluator.get_optimization_insights())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T18:11:34.174055Z","iopub.status.idle":"2025-04-19T18:11:34.174331Z","shell.execute_reply.started":"2025-04-19T18:11:34.174199Z","shell.execute_reply":"2025-04-19T18:11:34.174215Z"},"id":"0tc1zvFKEbwf"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"experiment_results = rag.grid_search(\n    questions=questions,\n    gold_answers=gold_answers,\n    chunk_sizes=[100, 250, 500, 800, 1000],\n    k_values=[3, 4, 5],\n    search_types=[\"semantic\", \"hybrid\", \"keyword\"],\n    chunk_overlaps=[100, 200],\n    # output_csv_path=\"/content/rag_grid_log.csv\"\n    output_csv_path=\"/kaggle/working/rag_grid_log.csv\"\n)","metadata":{"execution":{"iopub.status.busy":"2025-04-19T18:14:21.676582Z","iopub.execute_input":"2025-04-19T18:14:21.676864Z","iopub.status.idle":"2025-04-19T18:14:38.439437Z","shell.execute_reply.started":"2025-04-19T18:14:21.676845Z","shell.execute_reply":"2025-04-19T18:14:38.438264Z"},"id":"7_CDByMKxLEO","trusted":true},"outputs":[{"name":"stdout","text":"📄 Loading documents...\n✅ Loaded 101 document pages.\n🪓 Chunking documents...\n✅ Created 1010 chunks.\n📦 Creating vector store...\n🔎 Creating BM25 index...\n\n🔬 Running Config: chunk250_overlap100_semantic_k3\n⚠️ Error in config chunk250_overlap100_semantic_k3 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap100_semantic_k4\n⚠️ Error in config chunk250_overlap100_semantic_k4 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap100_semantic_k5\n⚠️ Error in config chunk250_overlap100_semantic_k5 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap100_hybrid_k3\n⚠️ Error in config chunk250_overlap100_hybrid_k3 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap100_hybrid_k4\n⚠️ Error in config chunk250_overlap100_hybrid_k4 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap100_hybrid_k5\n⚠️ Error in config chunk250_overlap100_hybrid_k5 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap100_keyword_k3\n⚠️ Error in config chunk250_overlap100_keyword_k3 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap100_keyword_k4\n⚠️ Error in config chunk250_overlap100_keyword_k4 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap100_keyword_k5\n⚠️ Error in config chunk250_overlap100_keyword_k5 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n📄 Loading documents...\n✅ Loaded 101 document pages.\n🪓 Chunking documents...\n✅ Created 1598 chunks.\n📦 Creating vector store...\n🔎 Creating BM25 index...\n\n🔬 Running Config: chunk250_overlap200_semantic_k3\n⚠️ Error in config chunk250_overlap200_semantic_k3 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap200_semantic_k4\n⚠️ Error in config chunk250_overlap200_semantic_k4 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap200_semantic_k5\n⚠️ Error in config chunk250_overlap200_semantic_k5 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap200_hybrid_k3\n⚠️ Error in config chunk250_overlap200_hybrid_k3 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap200_hybrid_k4\n⚠️ Error in config chunk250_overlap200_hybrid_k4 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap200_hybrid_k5\n⚠️ Error in config chunk250_overlap200_hybrid_k5 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap200_keyword_k3\n⚠️ Error in config chunk250_overlap200_keyword_k3 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap200_keyword_k4\n⚠️ Error in config chunk250_overlap200_keyword_k4 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n\n🔬 Running Config: chunk250_overlap200_keyword_k5\n⚠️ Error in config chunk250_overlap200_keyword_k5 for question 'What is Dynamic Programming?': ❌ LLM not initialized. Run initialize_llm().\n📄 Loading documents...\n✅ Loaded 101 document pages.\n🪓 Chunking documents...\n✅ Created 444 chunks.\n📦 Creating vector store...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_31/3058710266.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m experiment_results = rag.grid_search(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mquestions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mgold_answers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgold_answers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mchunk_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mk_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/1943814555.py\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(self, questions, gold_answers, chunk_sizes, k_values, search_types, chunk_overlaps, semantic_weight, keyword_weight, output_csv_path)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_process_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_retrieval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                     \u001b[0mevaluator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/1943814555.py\u001b[0m in \u001b[0;36minitialize_retrieval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"📦 Creating vector store...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectordb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_vector_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"🔎 Creating BM25 index...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/637664786.py\u001b[0m in \u001b[0;36mcreate_vector_store\u001b[0;34m(chunks, embedding_model, save_path)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \"\"\"\n\u001b[1;32m     17\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHuggingFaceEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mvectordb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/vectorstores/base.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                 \u001b[0mfaiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \"\"\"\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m         return cls.__from(\n\u001b[1;32m   1045\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_community/embeddings/huggingface.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0msentence_transformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_multi_process_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             embeddings = self.client.encode(\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_progress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m                     \u001b[0;31m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_numpy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m                         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m                 \u001b[0mall_embeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":40}]}