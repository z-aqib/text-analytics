{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11345061,"sourceType":"datasetVersion","datasetId":7098504},{"sourceId":11439657,"sourceType":"datasetVersion","datasetId":7166003},{"sourceId":11439662,"sourceType":"datasetVersion","datasetId":7166008}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"widgets":{"application/vnd.jupyter.widget-state+json":{"0efffe46e4c643f6b5c4d802819036ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2fe1553615e4464b8fa20e2c21bdf2fc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41fd2a4bf25949aaba088d8c56fdc3f0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_42df8db8a14642058d9b2255b0484497","placeholder":"​","style":"IPY_MODEL_49082566a2ac43a0b8e446809ce5f89b","value":"Evaluating: 100%"}},"42df8db8a14642058d9b2255b0484497":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49082566a2ac43a0b8e446809ce5f89b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b3fc3dddba44c07b2c3be73cb3034a0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e5948865f464a0aa72222fc4776c5fd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6809c0a0878d421ba3715ab62985bf6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2fe1553615e4464b8fa20e2c21bdf2fc","placeholder":"​","style":"IPY_MODEL_fccd27c6902b403cb6dca4fb3732851c","value":" 5/5 [01:48&lt;00:00, 12.67s/it]"}},"dfd48c084331419091adcd5d85872a82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5b3fc3dddba44c07b2c3be73cb3034a0","max":5,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0efffe46e4c643f6b5c4d802819036ac","value":5}},"fccd27c6902b403cb6dca4fb3732851c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd5bf3101ceb462998b0bc310efe1bf5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_41fd2a4bf25949aaba088d8c56fdc3f0","IPY_MODEL_dfd48c084331419091adcd5d85872a82","IPY_MODEL_6809c0a0878d421ba3715ab62985bf6d"],"layout":"IPY_MODEL_5e5948865f464a0aa72222fc4776c5fd"}}}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Acknowledgement\nName: Hamna Inam, Zara Masood, Zuha Aqib     \nERP ID: X, Y, 26106    \nSection: 10am Miss Solat    \nDate: 16-Apr-25   ","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\nprint(\"Last time code executed:\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:53:20.035311Z","iopub.execute_input":"2025-04-18T17:53:20.035596Z","iopub.status.idle":"2025-04-18T17:53:20.043438Z","shell.execute_reply.started":"2025-04-18T17:53:20.035566Z","shell.execute_reply":"2025-04-18T17:53:20.042574Z"}},"outputs":[{"name":"stdout","text":"Last time code executed: 2025-04-18 17:53:20\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"def print_date_time():\n    return \"\", datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:53:20.044281Z","iopub.execute_input":"2025-04-18T17:53:20.044532Z","iopub.status.idle":"2025-04-18T17:53:20.059792Z","shell.execute_reply.started":"2025-04-18T17:53:20.044507Z","shell.execute_reply":"2025-04-18T17:53:20.059250Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Imports\nhere we add all imports and prerequisities like installations, authentications, constant definitions etc","metadata":{}},{"cell_type":"markdown","source":"## Installations\nfirst we need to install related packages","metadata":{}},{"cell_type":"code","source":"# adding this because kaggle ke maslay\n!pip uninstall -y langchain langchain-core langchain-community langchain-openai ragas pydantic","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:53:20.061393Z","iopub.execute_input":"2025-04-18T17:53:20.061583Z","iopub.status.idle":"2025-04-18T17:53:27.621985Z","shell.execute_reply.started":"2025-04-18T17:53:20.061567Z","shell.execute_reply":"2025-04-18T17:53:27.621276Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: langchain 0.3.18\nUninstalling langchain-0.3.18:\n  Successfully uninstalled langchain-0.3.18\nFound existing installation: langchain-core 0.3.35\nUninstalling langchain-core-0.3.35:\n  Successfully uninstalled langchain-core-0.3.35\n\u001b[33mWARNING: Skipping langchain-community as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping langchain-openai as it is not installed.\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Skipping ragas as it is not installed.\u001b[0m\u001b[33m\n\u001b[0mFound existing installation: pydantic 2.11.3\nUninstalling pydantic-2.11.3:\n  Successfully uninstalled pydantic-2.11.3\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"get_ipython().system('pip install transformers')\nget_ipython().system('pip install sentence-transformers')\nget_ipython().system('pip install ragas')\nget_ipython().system('pip install pypdf')\nget_ipython().system('pip install pymupdf')\nget_ipython().system('pip install \"langchain==0.2.0\"')\nget_ipython().system('pip install rank_bm25')\nget_ipython().system('pip install datasets')\nget_ipython().system('pip install matplotlib')\nget_ipython().system('pip install faiss')\nget_ipython().system('pip install faiss-cpu')\nget_ipython().system('pip install faiss-gpu')\nget_ipython().system('pip install --upgrade langchain-community')\nget_ipython().system('pip install --upgrade pypdf')\nget_ipython().system('pip install pydantic==1.10.7')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:53:27.623072Z","iopub.execute_input":"2025-04-18T17:53:27.623409Z","iopub.status.idle":"2025-04-18T17:55:56.234933Z","shell.execute_reply.started":"2025-04-18T17:53:27.623376Z","shell.execute_reply":"2025-04-18T17:55:56.234196Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.5.1+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nCollecting ragas\n  Downloading ragas-0.2.14-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ragas) (1.26.4)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from ragas) (3.5.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ragas) (0.9.0)\nCollecting langchain (from ragas)\n  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\nCollecting langchain-core (from ragas)\n  Downloading langchain_core-0.3.54-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain-community (from ragas)\n  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\nCollecting langchain_openai (from ragas)\n  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ragas) (1.6.0)\nCollecting appdirs (from ragas)\n  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\nCollecting pydantic>=2 (from ragas)\n  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: openai>1 in /usr/local/lib/python3.11/dist-packages (from ragas) (1.61.1)\nCollecting diskcache>=5.6.3 (from ragas)\n  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (0.8.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas) (4.13.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas) (0.4.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->ragas)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (3.11.16)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas) (6.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->ragas) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->ragas) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->ragas) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->ragas) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->ragas) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->ragas) (2.4.1)\nCollecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain->ragas)\n  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas) (0.3.8)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas) (2.0.38)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core->ragas) (9.0.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core->ragas) (1.33)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community->ragas) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community->ragas)\n  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community->ragas)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting openai>1 (from ragas)\n  Downloading openai-1.75.0-py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->ragas) (2024.11.6)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas) (1.19.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas) (3.10)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (0.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain->ragas) (0.23.0)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community->ragas)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->ragas) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->ragas) (2.3.0)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain->ragas) (3.1.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ragas) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ragas) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->ragas) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->ragas) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas) (2025.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->ragas) (2024.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas) (1.17.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas) (1.0.0)\nDownloading ragas-0.2.14-py3-none-any.whl (187 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.6/443.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\nDownloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.54-py3-none-any.whl (433 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading openai-1.75.0-py3-none-any.whl (646 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\nDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m89.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nInstalling collected packages: appdirs, python-dotenv, httpx-sse, fsspec, diskcache, pydantic, pydantic-settings, openai, langchain-core, langchain-text-splitters, langchain_openai, langchain, langchain-community, ragas\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n  Attempting uninstall: openai\n    Found existing installation: openai 1.61.1\n    Uninstalling openai-1.61.1:\n      Successfully uninstalled openai-1.61.1\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.6\n    Uninstalling langchain-text-splitters-0.3.6:\n      Successfully uninstalled langchain-text-splitters-0.3.6\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsigstore 3.6.1 requires rich~=13.0, but you have rich 14.0.0 which is incompatible.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed appdirs-1.4.4 diskcache-5.6.3 fsspec-2024.12.0 httpx-sse-0.4.0 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.54 langchain-text-splitters-0.3.8 langchain_openai-0.3.14 openai-1.75.0 pydantic-2.11.3 pydantic-settings-2.9.1 python-dotenv-1.1.0 ragas-0.2.14\nRequirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\nCollecting pymupdf\n  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\nDownloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymupdf\nSuccessfully installed pymupdf-1.25.5\nRequirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.21)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.54)\nRequirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.16)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.8)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\nRequirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (0.3.8)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.1)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.2->langchain-community) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\nCollecting rank_bm25\n  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (1.26.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rank_bm25) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rank_bm25) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rank_bm25) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rank_bm25) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rank_bm25) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rank_bm25) (2024.2.0)\nDownloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\nInstalling collected packages: rank_bm25\nSuccessfully installed rank_bm25-0.2.2\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: numpy<2,>=1.20 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1.20->matplotlib) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1.20->matplotlib) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1.20->matplotlib) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2,>=1.20->matplotlib) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2,>=1.20->matplotlib) (2024.2.0)\n\u001b[31mERROR: Could not find a version that satisfies the requirement faiss (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for faiss\u001b[0m\u001b[31m\n\u001b[0mCollecting faiss-cpu\n  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\nDownloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: faiss-cpu\nSuccessfully installed faiss-cpu-1.10.0\n\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.21)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.54)\nRequirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.16)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nRequirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\nRequirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.8)\nRequirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\nRequirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (0.3.8)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.1)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3,>=1.26.2->langchain-community) (2.4.1)\nRequirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3,>=1.26.2->langchain-community) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3,>=1.26.2->langchain-community) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3,>=1.26.2->langchain-community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\nRequirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\nCollecting pydantic==1.10.7\n  Downloading pydantic-1.10.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (145 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.4/145.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==1.10.7) (4.13.1)\nDownloading pydantic-1.10.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pydantic\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.11.3\n    Uninstalling pydantic-2.11.3:\n      Successfully uninstalled pydantic-2.11.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain 0.3.23 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.10.7 which is incompatible.\nlangchain-core 0.3.54 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.10.7 which is incompatible.\nragas 0.2.14 requires pydantic>=2, but you have pydantic 1.10.7 which is incompatible.\npydantic-settings 2.9.1 requires pydantic>=2.7.0, but you have pydantic 1.10.7 which is incompatible.\nsigstore 3.6.1 requires pydantic<3,>=2, but you have pydantic 1.10.7 which is incompatible.\nsigstore 3.6.1 requires rich~=13.0, but you have rich 14.0.0 which is incompatible.\nsigstore-rekor-types 0.0.18 requires pydantic[email]<3,>=2, but you have pydantic 1.10.7 which is incompatible.\nydata-profiling 4.16.1 requires pydantic>=2, but you have pydantic 1.10.7 which is incompatible.\nalbumentations 2.0.4 requires pydantic>=2.9.2, but you have pydantic 1.10.7 which is incompatible.\nwandb 0.19.6 requires pydantic<3,>=2.6, but you have pydantic 1.10.7 which is incompatible.\ngoogle-genai 0.8.0 requires pydantic<3.0.0dev,>=2.0.0, but you have pydantic 1.10.7 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pydantic-1.10.7\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# adding this as error in kaggle\n# First uninstall all conflicting versions\n!pip uninstall langchain langchain-core langchain-community -y\n\n# Then install compatible versions\n!pip install \"langchain==0.2.0\" \"langchain-core==0.2.0\" \"langchain-community==0.2.0\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:55:56.236159Z","iopub.execute_input":"2025-04-18T17:55:56.236914Z","iopub.status.idle":"2025-04-18T17:56:07.083097Z","shell.execute_reply.started":"2025-04-18T17:55:56.236886Z","shell.execute_reply":"2025-04-18T17:56:07.082301Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: langchain 0.3.23\nUninstalling langchain-0.3.23:\n  Successfully uninstalled langchain-0.3.23\nFound existing installation: langchain-core 0.3.54\nUninstalling langchain-core-0.3.54:\n  Successfully uninstalled langchain-core-0.3.54\nFound existing installation: langchain-community 0.3.21\nUninstalling langchain-community-0.3.21:\n  Successfully uninstalled langchain-community-0.3.21\nCollecting langchain==0.2.0\n  Downloading langchain-0.2.0-py3-none-any.whl.metadata (13 kB)\nCollecting langchain-core==0.2.0\n  Downloading langchain_core-0.2.0-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain-community==0.2.0\n  Downloading langchain_community-0.2.0-py3-none-any.whl.metadata (8.8 kB)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (2.0.38)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (3.11.16)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (0.6.7)\nCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.0)\n  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain==0.2.0)\n  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (1.10.7)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (2.32.3)\nCollecting tenacity<9.0.0,>=8.1.0 (from langchain==0.2.0)\n  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.2.0) (1.33)\nCollecting packaging<24.0,>=23.2 (from langchain-core==0.2.0)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.19.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.2.0) (3.0.0)\nINFO: pip is looking at multiple versions of langchain-text-splitters to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain==0.2.0)\n  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl.metadata (2.2 kB)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain==0.2.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain==0.2.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain==0.2.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain==0.2.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain==0.2.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain==0.2.0) (2.4.1)\nRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (4.13.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.0) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (0.14.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.2.0) (1.0.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1->langchain==0.2.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1->langchain==0.2.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1->langchain==0.2.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2,>=1->langchain==0.2.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2,>=1->langchain==0.2.0) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.3.1)\nDownloading langchain-0.2.0-py3-none-any.whl (973 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.2.0-py3-none-any.whl (307 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\nDownloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\nInstalling collected packages: tenacity, packaging, langsmith, langchain-core, langchain-text-splitters, langchain, langchain-community\n  Attempting uninstall: tenacity\n    Found existing installation: tenacity 9.0.0\n    Uninstalling tenacity-9.0.0:\n      Successfully uninstalled tenacity-9.0.0\n  Attempting uninstall: packaging\n    Found existing installation: packaging 24.2\n    Uninstalling packaging-24.2:\n      Successfully uninstalled packaging-24.2\n  Attempting uninstall: langsmith\n    Found existing installation: langsmith 0.3.8\n    Uninstalling langsmith-0.3.8:\n      Successfully uninstalled langsmith-0.3.8\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.8\n    Uninstalling langchain-text-splitters-0.3.8:\n      Successfully uninstalled langchain-text-splitters-0.3.8\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain-openai 0.3.14 requires langchain-core<1.0.0,>=0.3.53, but you have langchain-core 0.2.0 which is incompatible.\nragas 0.2.14 requires pydantic>=2, but you have pydantic 1.10.7 which is incompatible.\nydata-profiling 4.16.1 requires pydantic>=2, but you have pydantic 1.10.7 which is incompatible.\nnilearn 0.11.1 requires scikit-learn>=1.4.0, but you have scikit-learn 1.2.2 which is incompatible.\npandas-gbq 0.26.1 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.2.0 langchain-community-0.2.0 langchain-core-0.2.0 langchain-text-splitters-0.2.1 langsmith-0.1.147 packaging-23.2 tenacity-8.5.0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Run these commands one by one in separate cells:\n\n# 1. First clean up\n!pip uninstall langchain langchain-core langchain-community langchain-openai ragas pydantic -y\n\n# 2. Then install\n!pip install \"langchain==0.2.0\"\n!pip install \"langchain-core==0.2.0\"\n!pip install \"langchain-community==0.2.0\"\n!pip install \"langchain-text-splitters==0.2.1\"\n!pip install \"langchain-openai==0.1.0\"\n!pip install \"pydantic==2.6.4\"\n!pip install \"ragas==0.2.14\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:56:07.084108Z","iopub.execute_input":"2025-04-18T17:56:07.084479Z","iopub.status.idle":"2025-04-18T17:56:42.738001Z","shell.execute_reply.started":"2025-04-18T17:56:07.084451Z","shell.execute_reply":"2025-04-18T17:56:42.737326Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: langchain 0.2.0\nUninstalling langchain-0.2.0:\n  Successfully uninstalled langchain-0.2.0\nFound existing installation: langchain-core 0.2.0\nUninstalling langchain-core-0.2.0:\n  Successfully uninstalled langchain-core-0.2.0\nFound existing installation: langchain-community 0.2.0\nUninstalling langchain-community-0.2.0:\n  Successfully uninstalled langchain-community-0.2.0\nFound existing installation: langchain-openai 0.3.14\nUninstalling langchain-openai-0.3.14:\n  Successfully uninstalled langchain-openai-0.3.14\nFound existing installation: ragas 0.2.14\nUninstalling ragas-0.2.14:\n  Successfully uninstalled ragas-0.2.14\nFound existing installation: pydantic 1.10.7\nUninstalling pydantic-1.10.7:\n  Successfully uninstalled pydantic-1.10.7\nCollecting langchain==0.2.0\n  Using cached langchain-0.2.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (2.0.38)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (3.11.16)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (0.6.7)\nCollecting langchain-core<0.3.0,>=0.2.0 (from langchain==0.2.0)\n  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (0.2.1)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (0.1.147)\nRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (1.26.4)\nCollecting pydantic<3,>=1 (from langchain==0.2.0)\n  Using cached pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (2.32.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.2.0) (8.5.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.2.0) (1.19.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain==0.2.0) (0.9.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (1.33)\nRequirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (23.2)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (4.13.1)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain==0.2.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain==0.2.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain==0.2.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain==0.2.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain==0.2.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain==0.2.0) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain==0.2.0) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.2.0) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.2.0) (3.1.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain==0.2.0) (3.0.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain==0.2.0) (1.0.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1->langchain==0.2.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1->langchain==0.2.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1->langchain==0.2.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2,>=1->langchain==0.2.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2,>=1->langchain==0.2.0) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.2.0) (1.3.1)\nUsing cached langchain-0.2.0-py3-none-any.whl (973 kB)\nDownloading langchain_core-0.2.43-py3-none-any.whl (397 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.1/397.1 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hUsing cached pydantic-2.11.3-py3-none-any.whl (443 kB)\nInstalling collected packages: pydantic, langchain-core, langchain\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nsigstore 3.6.1 requires rich~=13.0, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.2.0 langchain-core-0.2.43 pydantic-2.11.3\nCollecting langchain-core==0.2.0\n  Using cached langchain_core-0.2.0-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.2.0) (6.0.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.2.0) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.2.0) (0.1.147)\nRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.2.0) (23.2)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.2.0) (2.11.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core==0.2.0) (8.5.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core==0.2.0) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core==0.2.0) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core==0.2.0) (3.10.15)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core==0.2.0) (2.32.3)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core==0.2.0) (1.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core==0.2.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core==0.2.0) (2.33.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core==0.2.0) (4.13.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core==0.2.0) (0.4.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core==0.2.0) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core==0.2.0) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core==0.2.0) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core==0.2.0) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core==0.2.0) (0.14.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core==0.2.0) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core==0.2.0) (2.3.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core==0.2.0) (1.3.1)\nUsing cached langchain_core-0.2.0-py3-none-any.whl (307 kB)\nInstalling collected packages: langchain-core\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.2.43\n    Uninstalling langchain-core-0.2.43:\n      Successfully uninstalled langchain-core-0.2.43\nSuccessfully installed langchain-core-0.2.0\nCollecting langchain-community==0.2.0\n  Using cached langchain_community-0.2.0-py3-none-any.whl.metadata (8.8 kB)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (6.0.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (2.0.38)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (3.11.16)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.6.7)\nRequirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.2.0)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.2.0)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (0.1.147)\nRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (1.26.4)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (2.32.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community==0.2.0) (8.5.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.0) (1.19.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.2.1)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (2.11.3)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (1.33)\nRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (23.2)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.0.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain-community==0.2.0) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain-community==0.2.0) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain-community==0.2.0) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain-community==0.2.0) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain-community==0.2.0) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2,>=1->langchain-community==0.2.0) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community==0.2.0) (2025.1.31)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.2.0) (3.1.1)\nRequirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.2.0) (4.13.1)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (3.7.1)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community==0.2.0) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community==0.2.0) (0.4.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.0) (1.0.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1->langchain-community==0.2.0) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2,>=1->langchain-community==0.2.0) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2,>=1->langchain-community==0.2.0) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2,>=1->langchain-community==0.2.0) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2,>=1->langchain-community==0.2.0) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-community==0.2.0) (1.3.1)\nUsing cached langchain_community-0.2.0-py3-none-any.whl (2.1 MB)\nInstalling collected packages: langchain-community\nSuccessfully installed langchain-community-0.2.0\nRequirement already satisfied: langchain-text-splitters==0.2.1 in /usr/local/lib/python3.11/dist-packages (0.2.1)\nRequirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-text-splitters==0.2.1) (0.2.0)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (6.0.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (0.1.147)\nRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (23.2)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (2.11.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (8.5.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (3.10.15)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (2.32.3)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (1.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (2.33.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (4.13.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (0.4.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (3.7.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (1.0.7)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (3.10)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (0.14.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.0->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (2.3.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.3.0,>=0.2.0->langchain-text-splitters==0.2.1) (1.3.1)\nCollecting langchain-openai==0.1.0\n  Downloading langchain_openai-0.1.0-py3-none-any.whl.metadata (2.5 kB)\nCollecting langchain-core<0.2.0,>=0.1.33 (from langchain-openai==0.1.0)\n  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.1.0) (1.75.0)\nRequirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.1.0) (0.9.0)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai==0.1.0) (6.0.2)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai==0.1.0) (1.33)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai==0.1.0) (0.1.147)\nRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai==0.1.0) (23.2)\nRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai==0.1.0) (2.11.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai==0.1.0) (8.5.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.0) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.0) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.0) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.0) (0.8.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.0) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.0) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.10.0->langchain-openai==0.1.0) (4.13.1)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.0) (2024.11.6)\nRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.5.2->langchain-openai==0.1.0) (2.32.3)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.0) (3.10)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.0) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.0) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai==0.1.0) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain-openai==0.1.0) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.33->langchain-openai==0.1.0) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.33->langchain-openai==0.1.0) (1.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai==0.1.0) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai==0.1.0) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-openai==0.1.0) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.0) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai==0.1.0) (2.3.0)\n\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'langchain-openai' candidate (version 0.1.0 at https://files.pythonhosted.org/packages/6d/f4/bea64066e93a4980f0d8352af733f950ff0eea98cca5000a4ca1ff2ae2b8/langchain_openai-0.1.0-py3-none-any.whl (from https://pypi.org/simple/langchain-openai/) (requires-python:<4.0,>=3.8.1))\nReason for being yanked: Contained a regression that prevented passing ToolMessage in the input to ChatOpenAI, fixed in 0.1.1\u001b[0m\u001b[33m\n\u001b[0mDownloading langchain_openai-0.1.0-py3-none-any.whl (32 kB)\nDownloading langchain_core-0.1.53-py3-none-any.whl (303 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.1/303.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: langchain-core, langchain-openai\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.2.0\n    Uninstalling langchain-core-0.2.0:\n      Successfully uninstalled langchain-core-0.2.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain-text-splitters 0.2.1 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.1.53 which is incompatible.\nlangchain-community 0.2.0 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.1.53 which is incompatible.\nlangchain 0.2.0 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.1.53 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-core-0.1.53 langchain-openai-0.1.0\nCollecting pydantic==2.6.4\n  Downloading pydantic-2.6.4-py3-none-any.whl.metadata (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.1/85.1 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.6.4) (0.7.0)\nCollecting pydantic-core==2.16.3 (from pydantic==2.6.4)\n  Downloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\nRequirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.6.4) (4.13.1)\nDownloading pydantic-2.6.4-py3-none-any.whl (394 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pydantic_core-2.16.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pydantic-core, pydantic\n  Attempting uninstall: pydantic-core\n    Found existing installation: pydantic_core 2.33.1\n    Uninstalling pydantic_core-2.33.1:\n      Successfully uninstalled pydantic_core-2.33.1\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 2.11.3\n    Uninstalling pydantic-2.11.3:\n      Successfully uninstalled pydantic-2.11.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlangchain-community 0.2.0 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.1.53 which is incompatible.\nlangchain 0.2.0 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.1.53 which is incompatible.\npydantic-settings 2.9.1 requires pydantic>=2.7.0, but you have pydantic 2.6.4 which is incompatible.\nsigstore 3.6.1 requires rich~=13.0, but you have rich 14.0.0 which is incompatible.\nalbumentations 2.0.4 requires pydantic>=2.9.2, but you have pydantic 2.6.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pydantic-2.6.4 pydantic-core-2.16.3\nCollecting ragas==0.2.14\n  Using cached ragas-0.2.14-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ragas==0.2.14) (1.26.4)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from ragas==0.2.14) (3.5.0)\nRequirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from ragas==0.2.14) (0.9.0)\nRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (from ragas==0.2.14) (0.2.0)\nRequirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (from ragas==0.2.14) (0.1.53)\nRequirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (from ragas==0.2.14) (0.2.0)\nRequirement already satisfied: langchain_openai in /usr/local/lib/python3.11/dist-packages (from ragas==0.2.14) (0.1.0)\nRequirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ragas==0.2.14) (1.6.0)\nRequirement already satisfied: appdirs in /usr/local/lib/python3.11/dist-packages (from ragas==0.2.14) (1.4.4)\nRequirement already satisfied: pydantic>=2 in /usr/local/lib/python3.11/dist-packages (from ragas==0.2.14) (2.6.4)\nRequirement already satisfied: openai>1 in /usr/local/lib/python3.11/dist-packages (from ragas==0.2.14) (1.75.0)\nRequirement already satisfied: diskcache>=5.6.3 in /usr/local/lib/python3.11/dist-packages (from ragas==0.2.14) (5.6.3)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas==0.2.14) (3.7.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas==0.2.14) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas==0.2.14) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas==0.2.14) (0.8.2)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas==0.2.14) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas==0.2.14) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>1->ragas==0.2.14) (4.13.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas==0.2.14) (0.7.0)\nRequirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2->ragas==0.2.14) (2.16.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets->ragas==0.2.14) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas==0.2.14) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas==0.2.14) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->ragas==0.2.14) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas==0.2.14) (2.32.3)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->ragas==0.2.14) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas==0.2.14) (0.70.16)\nRequirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->ragas==0.2.14) (2024.12.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->ragas==0.2.14) (3.11.16)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas==0.2.14) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->ragas==0.2.14) (23.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->ragas==0.2.14) (6.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->ragas==0.2.14) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->ragas==0.2.14) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->ragas==0.2.14) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->ragas==0.2.14) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->ragas==0.2.14) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->ragas==0.2.14) (2.4.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas==0.2.14) (2.0.38)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas==0.2.14) (0.6.7)\nCollecting langchain-core (from ragas==0.2.14)\n  Using cached langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\nRequirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas==0.2.14) (0.2.1)\nRequirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas==0.2.14) (0.1.147)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain->ragas==0.2.14) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core->ragas==0.2.14) (1.33)\nINFO: pip is looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\nCollecting langchain_openai (from ragas==0.2.14)\n  Using cached langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n  Downloading langchain_openai-0.3.13-py3-none-any.whl.metadata (2.3 kB)\n  Downloading langchain_openai-0.3.12-py3-none-any.whl.metadata (2.3 kB)\n  Downloading langchain_openai-0.3.11-py3-none-any.whl.metadata (2.3 kB)\n  Downloading langchain_openai-0.3.10-py3-none-any.whl.metadata (2.3 kB)\n  Downloading langchain_openai-0.3.9-py3-none-any.whl.metadata (2.3 kB)\n  Downloading langchain_openai-0.3.8-py3-none-any.whl.metadata (2.3 kB)\nINFO: pip is still looking at multiple versions of langchain-openai to determine which version is compatible with other requirements. This could take a while.\n  Downloading langchain_openai-0.3.7-py3-none-any.whl.metadata (2.3 kB)\n  Downloading langchain_openai-0.3.6-py3-none-any.whl.metadata (2.3 kB)\n  Downloading langchain_openai-0.3.5-py3-none-any.whl.metadata (2.3 kB)\n  Downloading langchain_openai-0.3.4-py3-none-any.whl.metadata (2.3 kB)\n  Downloading langchain_openai-0.3.3-py3-none-any.whl.metadata (2.7 kB)\nINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n  Downloading langchain_openai-0.3.2-py3-none-any.whl.metadata (2.7 kB)\n  Downloading langchain_openai-0.3.1-py3-none-any.whl.metadata (2.7 kB)\n  Downloading langchain_openai-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n  Downloading langchain_openai-0.2.14-py3-none-any.whl.metadata (2.7 kB)\n  Downloading langchain_openai-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n  Downloading langchain_openai-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n  Downloading langchain_openai-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n  Downloading langchain_openai-0.2.10-py3-none-any.whl.metadata (2.6 kB)\n  Downloading langchain_openai-0.2.9-py3-none-any.whl.metadata (2.6 kB)\n  Downloading langchain_openai-0.2.8-py3-none-any.whl.metadata (2.6 kB)\n  Downloading langchain_openai-0.2.7-py3-none-any.whl.metadata (2.6 kB)\n  Downloading langchain_openai-0.2.6-py3-none-any.whl.metadata (2.6 kB)\n  Downloading langchain_openai-0.2.5-py3-none-any.whl.metadata (2.6 kB)\n  Downloading langchain_openai-0.2.4-py3-none-any.whl.metadata (2.6 kB)\n  Downloading langchain_openai-0.2.3-py3-none-any.whl.metadata (2.6 kB)\n  Downloading langchain_openai-0.2.2-py3-none-any.whl.metadata (2.6 kB)\n  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n  Downloading langchain_openai-0.1.25-py3-none-any.whl.metadata (2.6 kB)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->ragas==0.2.14) (2024.11.6)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas==0.2.14) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas==0.2.14) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas==0.2.14) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas==0.2.14) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas==0.2.14) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas==0.2.14) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->ragas==0.2.14) (1.19.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai>1->ragas==0.2.14) (3.10)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->ragas==0.2.14) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->ragas==0.2.14) (0.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.2.14) (2025.1.31)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai>1->ragas==0.2.14) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>1->ragas==0.2.14) (0.14.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core->ragas==0.2.14) (3.0.0)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas==0.2.14) (3.10.15)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain->ragas==0.2.14) (1.0.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->ragas==0.2.14) (3.4.1)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets->ragas==0.2.14) (2.3.0)\nRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain->ragas==0.2.14) (3.1.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ragas==0.2.14) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->ragas==0.2.14) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->ragas==0.2.14) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->ragas==0.2.14) (2024.2.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas==0.2.14) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas==0.2.14) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->ragas==0.2.14) (2025.2)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->ragas==0.2.14) (2024.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->ragas==0.2.14) (1.17.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->ragas==0.2.14) (1.0.0)\nUsing cached ragas-0.2.14-py3-none-any.whl (187 kB)\nUsing cached langchain_core-0.2.43-py3-none-any.whl (397 kB)\nDownloading langchain_openai-0.1.25-py3-none-any.whl (51 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: langchain-core, langchain_openai, ragas\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.1.53\n    Uninstalling langchain-core-0.1.53:\n      Successfully uninstalled langchain-core-0.1.53\n  Attempting uninstall: langchain_openai\n    Found existing installation: langchain-openai 0.1.0\n    Uninstalling langchain-openai-0.1.0:\n      Successfully uninstalled langchain-openai-0.1.0\nSuccessfully installed langchain-core-0.2.43 langchain_openai-0.1.25 ragas-0.2.14\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Imports\nhere we import the necessary libraries and modules","metadata":{}},{"cell_type":"code","source":"# ===== Environment & Authentication =====\nimport os\nimport time\nimport csv\n# from dotenv import load_dotenv, dotenv_values\nfrom huggingface_hub import login\n\n# ===== Core Python & Data Handling =====\nfrom typing import List, Tuple, Dict\nimport textwrap\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# ===== NLP Preprocessing =====\nimport nltk\nfrom rank_bm25 import BM25Okapi  # BM25 retriever\nnltk.download('punkt')  # Ensure NLTK data is available\n\n# ===== LangChain - Document Loading & Splitting =====\nfrom langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n# from langchain.schema import Document\nfrom langchain_core.documents import Document\n\n# ===== LangChain - Embeddings & Vector Stores =====\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import FAISS\n\n# ===== Hugging Face Models & Pipelines =====\nfrom transformers import (\n    AutoModelForCausalLM, \n    AutoTokenizer, \n    pipeline\n)\nfrom langchain.llms import (\n    HuggingFaceHub, \n    HuggingFacePipeline\n)\n\n# ===== RAG Evaluation (RAGAS) =====\nfrom ragas import evaluate\nfrom ragas.metrics import (\n    Faithfulness,\n    AnswerRelevancy,\n    ContextRecall,\n    ContextPrecision,\n    AnswerCorrectness\n)\nfrom datasets import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:56:42.738972Z","iopub.execute_input":"2025-04-18T17:56:42.739182Z","iopub.status.idle":"2025-04-18T17:57:23.363956Z","shell.execute_reply.started":"2025-04-18T17:56:42.739162Z","shell.execute_reply":"2025-04-18T17:57:23.363300Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n2025-04-18 17:57:03.561718: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1744999023.962467      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1744999024.075430      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# because there was an error in this import, here it is seperatly\nimport torch\nprint(torch.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:57:23.364693Z","iopub.execute_input":"2025-04-18T17:57:23.365314Z","iopub.status.idle":"2025-04-18T17:57:23.370006Z","shell.execute_reply.started":"2025-04-18T17:57:23.365287Z","shell.execute_reply":"2025-04-18T17:57:23.369143Z"}},"outputs":[{"name":"stdout","text":"2.5.1+cu124\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from packaging import version\n\n# Check torch version (modern alternative)\ndef is_torch_greater_or_equal_than_1_13():\n    return version.parse(torch.__version__) >= version.parse(\"1.13.0\")\n\nprint(f\"Torch version: {torch.__version__}\")\nprint(f\"Is >=1.13.0: {is_torch_greater_or_equal_than_1_13()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:57:23.372449Z","iopub.execute_input":"2025-04-18T17:57:23.372676Z","iopub.status.idle":"2025-04-18T17:57:23.395458Z","shell.execute_reply.started":"2025-04-18T17:57:23.372654Z","shell.execute_reply":"2025-04-18T17:57:23.394701Z"}},"outputs":[{"name":"stdout","text":"Torch version: 2.5.1+cu124\nIs >=1.13.0: True\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"## Authentication\nhere we authenticate our LLM with hugging face","metadata":{}},{"cell_type":"code","source":"# # Load environment variables from .env\n# load_dotenv()\n\n# # Retrieve the token\n# hf_token = os.getenv(\"HUGGING_FACE_TOKEN\")\n\n# print(\"Token loaded:\", hf_token is not None)\n\n# # Log in to Hugging Face Hub\nlogin(token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:57:23.396300Z","iopub.execute_input":"2025-04-18T17:57:23.396541Z","iopub.status.idle":"2025-04-18T17:57:23.539520Z","shell.execute_reply.started":"2025-04-18T17:57:23.396524Z","shell.execute_reply":"2025-04-18T17:57:23.538735Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# config = dotenv_values(\".env\")\n# login(token=config[\"HUGGING_FACE_TOKEN\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T17:57:23.540413Z","iopub.execute_input":"2025-04-18T17:57:23.540700Z","iopub.status.idle":"2025-04-18T17:57:23.544032Z","shell.execute_reply.started":"2025-04-18T17:57:23.540678Z","shell.execute_reply":"2025-04-18T17:57:23.543398Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Constants\nhere we define constants that we will fine tune","metadata":{}},{"cell_type":"code","source":"# Constants\nDEFAULT_CHUNK_SIZE = 1000              # Max size of each text chunk\nDEFAULT_CHUNK_OVERLAP = 200            # Overlap between chunks\nDEFAULT_SEARCH_K = 3                   # Top-k results to retrieve\nDEFAULT_SEARCH_TYPE = \"hybrid\"         # Choose from: 'semantic', 'keyword', or 'hybrid'\nDEFAULT_EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"  # Embedding model for vector search\nDEFAULT_LLM_MODEL = \"meta-llama/Llama-3.2-1B\"                         # LLM for generating answers\n# DEFAULT_LLM_MODEL = \"deepseek-ai/DeepSeek-V3-0324\"                         # LLM for generating answers\n# DEFAULT_DOCUMENT_DIR = \"/data/corpus.zip\"\nDEFAULT_DOCUMENT_DIR = \"/kaggle/input/daa-lectures-for-a4/cmu-lecs\"","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.002Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Document Processing Functions","metadata":{"id":"L1E1l1iNxLEF"}},{"cell_type":"code","source":"def load_documents(directory: str, glob_pattern: str = \"**/*.pdf\") -> List[Document]:\n    \"\"\"\n    Loads all PDF files from a given directory.\n    \n    Args:\n        directory: path to folder with PDF files\n        glob_pattern: pattern to match files (default = all PDFs)\n    \n    Returns:\n        List of LangChain Document objects\n    \"\"\"\n    loader = DirectoryLoader(directory, glob=glob_pattern, loader_cls=PyPDFLoader)\n    return loader.load()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def chunk_documents(\n    documents: List[Document],\n    chunk_size: int = DEFAULT_CHUNK_SIZE,\n    chunk_overlap: int = DEFAULT_CHUNK_OVERLAP,\n    separators: List[str] = None\n) -> List[Document]:\n    \"\"\"\n    Splits documents into chunks for better retrieval.\n    \n    Args:\n        documents: list of LangChain documents\n        chunk_size: size of each chunk\n        chunk_overlap: how much content overlaps between chunks\n        separators: optional list of separators for better splitting\n    \n    Returns:\n        List of chunked Document objects\n    \"\"\"\n    if separators is None:\n        # Default separators: prioritize splitting on paragraphs, then sentences, then words\n        separators = [\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=chunk_size,\n        chunk_overlap=chunk_overlap,\n        separators=separators\n    )\n    return text_splitter.split_documents(documents)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.005Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_vector_store(\n    chunks: List[Document],\n    embedding_model: str = DEFAULT_EMBEDDING_MODEL,\n    save_path: str = None\n) -> FAISS:\n    \"\"\"\n    Creates a FAISS vector index from document chunks using specified embedding model.\n    \n    Args:\n        chunks: list of Document chunks\n        embedding_model: HuggingFace model used for embeddings\n        save_path: optional path to save the index\n    \n    Returns:\n        FAISS vector store\n    \"\"\"\n    embeddings = HuggingFaceEmbeddings(model_name=embedding_model)\n    vectordb = FAISS.from_documents(chunks, embeddings)\n\n    if save_path:\n        vectordb.save_local(save_path)\n\n    return vectordb","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.006Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_bm25_index(chunks: List[Document]) -> BM25Okapi:\n    \"\"\"\n    Builds a keyword-based index using BM25.\n    \n    Args:\n        chunks: list of Document chunks\n    \n    Returns:\n        BM25 index\n    \"\"\"\n    texts = [chunk.page_content for chunk in chunks]                  # Get plain text\n    tokenized_texts = [text.split() for text in texts]               # Tokenize by whitespace\n    return BM25Okapi(tokenized_texts)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.006Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Search Functions","metadata":{"id":"p-gPSeFBxLEH"}},{"cell_type":"code","source":"def semantic_search(\n    query: str,\n    vectordb: FAISS,\n    k: int = DEFAULT_SEARCH_K,\n    score_threshold: float = None\n) -> List[Tuple[Document, float]]:\n    \"\"\"\n    Perform semantic search using vector similarity from FAISS.\n\n    Args:\n        query: Natural language question\n        vectordb: Vector index (FAISS)\n        k: Number of results to return\n        score_threshold: Filter out low similarity scores (optional)\n\n    Returns:\n        List of (Document, similarity_score) tuples\n    \"\"\"\n    results = vectordb.similarity_search_with_score(query, k=k)\n\n    # Optional thresholding to remove irrelevant results\n    if score_threshold is not None:\n        results = [(doc, score) for doc, score in results if score >= score_threshold]\n\n    return results","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def keyword_search(\n    query: str,\n    bm25_index: BM25Okapi,\n    chunks: List[Document],\n    k: int = DEFAULT_SEARCH_K,\n    score_threshold: float = None\n) -> List[Tuple[Document, float]]:\n    \"\"\"\n    Perform lexical search using BM25.\n\n    Args:\n        query: Search query string\n        bm25_index: Pre-built BM25 index\n        chunks: List of document chunks for mapping back\n        k: Top-k documents to retrieve\n        score_threshold: Optional filtering threshold for BM25 scores\n\n    Returns:\n        List of (Document, BM25_score) tuples\n    \"\"\"\n    tokenized_query = query.split()  # Basic whitespace tokenization\n    scores = bm25_index.get_scores(tokenized_query)\n\n    # Get indices of top-k documents\n    top_k_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:k]\n\n    results = [(chunks[i], scores[i]) for i in top_k_indices]\n\n    if score_threshold is not None:\n        results = [(doc, score) for doc, score in results if score >= score_threshold]\n\n    return results","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def hybrid_search(\n    query: str,\n    vectordb: FAISS,\n    bm25_index: BM25Okapi,\n    chunks: List[Document],\n    k: int = DEFAULT_SEARCH_K,\n    semantic_weight: float = 0.5,\n    keyword_weight: float = 0.5\n) -> List[Tuple[Document, float]]:\n    \"\"\"\n    Combine semantic and keyword search using weighted score fusion.\n\n    Args:\n        query: Natural language query\n        vectordb: FAISS vector database\n        bm25_index: BM25 keyword index\n        chunks: Document chunks (used for mapping back)\n        k: Top-k results to return\n        semantic_weight: Weight for vector similarity\n        keyword_weight: Weight for BM25 relevance\n\n    Returns:\n        List of (Document, combined_score) tuples\n    \"\"\"\n    # Step 1: Run both types of searches with larger k (to capture wider context)\n    semantic_results = semantic_search(query, vectordb, k * 2)\n    semantic_scores = {doc.page_content: score for doc, score in semantic_results}\n\n    keyword_results = keyword_search(query, bm25_index, chunks, k * 2)\n    keyword_scores = {doc.page_content: score for doc, score in keyword_results}\n\n    # Step 2: Normalize BM25 scores (they are not bounded, unlike cosine similarity)\n    max_kw_score = max(keyword_scores.values()) if keyword_scores else 1\n\n    # Step 3: Combine results\n    all_docs = set(semantic_scores.keys()).union(set(keyword_scores.keys()))\n    combined_scores = []\n\n    for doc_content in all_docs:\n        sem_score = semantic_scores.get(doc_content, 0)\n        kw_score = keyword_scores.get(doc_content, 0)\n        norm_kw_score = kw_score / max_kw_score if max_kw_score > 0 else 0\n\n        # Weighted sum of both types of scores\n        combined_score = (semantic_weight * sem_score) + (keyword_weight * norm_kw_score)\n        combined_scores.append((doc_content, combined_score))\n\n    # Step 4: Sort and return top-k\n    combined_scores.sort(key=lambda x: x[1], reverse=True)\n    top_scores = combined_scores[:k]\n\n    # Step 5: Re-map back to full Document objects using content\n    doc_lookup = {chunk.page_content: chunk for chunk in chunks}\n    results = []\n\n    for doc_content, score in top_scores:\n        if doc_content in doc_lookup:\n            results.append((doc_lookup[doc_content], score))\n\n    return results","metadata":{"execution":{"execution_failed":"2025-04-18T17:59:25.007Z"},"id":"J3T0XMX0xLEH","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# LLM functions","metadata":{"id":"7Q5NGOdUxLEI"}},{"cell_type":"code","source":"def initialize_llm(\n    model_name: str = DEFAULT_LLM_MODEL,\n    device: str = \"cuda\",  # Use \"cpu\" if not using GPU\n    max_new_tokens: int = 300\n) -> Tuple[pipeline, any]:\n    \"\"\"\n    Loads a language model pipeline for text generation.\n\n    Args:\n        model_name: HuggingFace model repo (must support causal LM)\n        device: \"cuda\" for GPU or \"cpu\"\n        max_new_tokens: Max tokens to generate per response\n\n    Returns:\n        Tuple (generator pipeline, tokenizer)\n    \"\"\"\n    try:\n        model = AutoModelForCausalLM.from_pretrained(\n            model_name,\n            device_map=device,\n            torch_dtype=\"auto\",            # Uses GPU acceleration if available\n            trust_remote_code=True         # Allow custom model architectures\n        )\n        print(\"Original used\")\n    except ImportError:\n        # Fallback without device_map\n        model = AutoModelForCausalLM.from_pretrained(\n            model_name,\n            torch_dtype=\"auto\",\n            trust_remote_code=True\n        ).to(device)\n        print(\"Edited used\")\n    \n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n    # Format the prompt as a dialogue (user + assistant style)\n    tokenizer.chat_template = (\n        \"{% for message in messages %}\"\n        \"{% if message['role'] == 'user' %}User: {{ message['content'] }}\\n\"\n        \"{% elif message['role'] == 'assistant' %}Assistant: {{ message['content'] }}\\n\"\n        \"{% endif %}\"\n        \"{% endfor %}\"\n        \"{% if add_generation_prompt %}Assistant:{% endif %}\"\n    )\n\n    # Create a text-generation pipeline\n    generator = pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        return_full_text=False,        # Only return generated part, not the full prompt\n        max_new_tokens=max_new_tokens,\n        do_sample=True                 # Use sampling (stochastic generation)\n    )\n\n    return generator, tokenizer","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_response(\n    prompt: str,\n    generator: pipeline,\n    width: int = 80  # For pretty-printing long outputs\n) -> str:\n    \"\"\"\n    Generates a response from the LLM using the prompt.\n\n    Args:\n        prompt: Full RAG-formatted prompt with question + context\n        generator: HF pipeline object\n        width: max characters per printed line (for wrapping)\n\n    Returns:\n        Answer string\n    \"\"\"\n    messages = [{\"role\": \"user\", \"content\": prompt}]        # Wrap prompt in chat message format\n    output = generator(\n        messages,\n        max_new_tokens=256,\n        temperature=0.7,\n        top_p=0.9,\n        do_sample=True\n    )\n                            # Call LLM\n    return textwrap.fill(output[0][\"generated_text\"], width=width)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.008Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def format_rag_prompt(\n    question: str,\n    retrieved_docs: List[Document],\n    instruction: str = None\n) -> str:\n    \"\"\"\n    Formats the final input prompt to send to the LLM.\n\n    Args:\n        question: The user's natural language question\n        retrieved_docs: List of document chunks retrieved by search\n        instruction: Optional prompt instructions (system message)\n\n    Returns:\n        Full prompt text string\n    \"\"\"\n    # Default instructions to guide the LLM on how to use retrieved documents\n    if instruction is None:\n        instruction = \"\"\"You are an AI assistant tasked with answering questions based on retrieved knowledge.\n                    - Integrate the key points from all retrieved responses into a cohesive, well-structured answer.\n                    - If the responses are contradictory, mention the different perspectives.\n                    - If none of the retrieved responses contain relevant information, reply:\n                    \"I couldn't find a good response to your query in the database.\"\n                    \"\"\"\n\n    # Truncate each document to 1000 characters if long\n    retrieved_info = \"\\n\\n\".join(\n        f\"{i+1}️⃣ {doc.page_content[:1000]}...\" if len(doc.page_content) > 1000\n        else f\"{i+1}️⃣ {doc.page_content}\"\n        for i, doc in enumerate(retrieved_docs)\n    )\n\n    # Final structured prompt\n    return f\"\"\"\n        {instruction}\n\n        ### Retrieved Information:\n        {retrieved_info}\n\n        ### Question:\n        {question}\n    \"\"\"","metadata":{"execution":{"execution_failed":"2025-04-18T17:59:25.008Z"},"id":"9GJIwleTxLEJ","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# RAG Evaluator","metadata":{"id":"07jDDqiSxLEJ"}},{"cell_type":"code","source":"# WRAPPER TO USE LANGCHAIN LLM IN RAGAS\n\nclass HuggingFaceLLM:\n    \"\"\"\n    Simple wrapper for using HuggingFaceHub with RAGAS evaluation.\n    \"\"\"\n    def __init__(self, model_name: str):\n        self.model = HuggingFaceHub(repo_id=model_name)\n\n    def __call__(self, prompt: str) -> str:\n        return self.model(prompt)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.009Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# EVALUATOR CLASS\n\nclass RAGEvaluator:\n    \"\"\"\n    Performs automatic evaluation of RAG responses using Ragas metrics.\n    Also supports result visualization and optimization insights.\n    \"\"\"\n    def __init__(self, pipeline, llm, embeddings):\n        self.pipeline = pipeline         # RAGPipeline object\n        self.embeddings = embeddings     # HuggingFaceEmbeddings instance\n\n        # Use passed LLM, or initialize default\n        if isinstance(llm, str):\n            self.llm = HuggingFaceHub(repo_id=llm)\n        else:\n            self.llm = llm or HuggingFaceHub(repo_id=DEFAULT_LLM_MODEL)\n\n        # Internal result tracking\n        self.results = []\n\n    def evaluate_ragas(self, questions: list, gold_answers: list = None):\n        \"\"\"\n        Run Ragas evaluation across all questions.\n\n        Args:\n            questions: List of input questions\n            gold_answers: Reference answers (optional)\n\n        Returns:\n            DataFrame of results\n        \"\"\"\n        all_rows = []\n\n        for question, gold_answer in zip(questions, gold_answers or [None]*len(questions)):\n            # Run full RAG query\n            answer = self.pipeline.query(question)\n\n            # Get context used in the answer\n            contexts = [doc.page_content for doc in self.pipeline.get_last_retrieved_docs()]\n\n            # Prepare a single sample for evaluation\n            data = {\n                \"question\": [question],\n                \"answer\": [answer],\n                \"contexts\": [contexts]\n            }\n            if gold_answer:\n                data[\"ground_truth\"] = [gold_answer]\n\n            dataset = Dataset.from_dict(data)\n\n            # Select metrics to compute\n            metrics = [Faithfulness(), AnswerRelevancy(), ContextRecall(), ContextPrecision()]\n            if gold_answer:\n                metrics.append(AnswerCorrectness())\n\n            # Run the evaluation\n            result = evaluate(dataset, metrics=metrics, llm=self.llm, embeddings=self.embeddings)\n\n            # Convert to DataFrame and store\n            row = result.to_pandas()\n            row[\"question\"] = question\n            row[\"retrieved_docs\"] = len(contexts)\n            all_rows.append(row)\n\n        # Combine all rows into one DataFrame\n        self.results = pd.concat(all_rows, ignore_index=True)\n        return self.results\n\n    def visualize_metrics(self):\n        \"\"\"\n        Visualize average metric scores and context retrieval stats.\n        \"\"\"\n        if self.results is None or self.results.empty:\n            raise ValueError(\"No evaluation results found. Run evaluate_ragas() first.\")\n\n        # Plot main metrics\n        metrics = ['faithfulness', 'answer_relevancy', 'context_recall', 'context_precision']\n        if 'answer_correctness' in self.results.columns:\n            metrics.append('answer_correctness')\n\n        plt.figure(figsize=(10, 5))\n        self.results[metrics].mean().plot(kind='bar', color='lightblue')\n        plt.title(\"🔍 Average RAG Evaluation Metrics\")\n        plt.ylabel(\"Score (0 to 1)\")\n        plt.xticks(rotation=45)\n        plt.grid(axis='y', linestyle='--', alpha=0.5)\n        plt.show()\n\n        # Plot document retrieval counts\n        plt.figure(figsize=(8, 4))\n        self.results['retrieved_docs'].value_counts().sort_index().plot(kind='bar', color='lightgreen')\n        plt.title(\"📄 Number of Context Chunks Retrieved Per Query\")\n        plt.xlabel(\"Number of Chunks\")\n        plt.ylabel(\"Frequency\")\n        plt.grid(axis='y', linestyle='--', alpha=0.5)\n        plt.show()\n\n    def get_optimization_insights(self):\n        \"\"\"\n        Analyze weak metrics and recommend strategies to improve RAG performance.\n        \"\"\"\n        if self.results is None or self.results.empty:\n            return \"No evaluation results available.\"\n\n        insights = []\n        df = self.results\n\n        # Faithfulness issues (hallucination)\n        if df['faithfulness'].mean() < 0.7:\n            insights.append(\"⚠️ Faithfulness is low — possible hallucinations.\")\n            insights.append(\"🔧 Try increasing chunk overlap or improving retrieval relevance.\")\n\n        # Context recall issues (missing info)\n        if df['context_recall'].mean() < 0.6:\n            insights.append(\"⚠️ Low context recall — relevant info may be missed.\")\n            insights.append(\"🔧 Consider using hybrid retrieval or adjusting chunk size.\")\n\n        # Precision issues (irrelevant info)\n        if df['context_precision'].mean() < 0.6:\n            insights.append(\"⚠️ Low context precision — too much irrelevant context.\")\n            insights.append(\"🔧 Use better embeddings or rerank retrieved chunks.\")\n\n        # Relevance issues (answer not matching question)\n        if df['answer_relevancy'].mean() < 0.7:\n            insights.append(\"⚠️ Low answer relevancy — answers not matching question.\")\n            insights.append(\"🔧 Refine your prompts or improve chunk matching.\")\n\n        # Optional: Correctness based on gold answers\n        if 'answer_correctness' in df.columns and df['answer_correctness'].mean() < 0.7:\n            insights.append(\"⚠️ Low correctness — answers differ from references.\")\n            insights.append(\"🔧 Try different LLMs or use post-editing.\")\n\n        return \"\\n\".join(insights)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DAFXSDHQxLEK","outputId":"b3c7855e-689a-4381-ebdb-06ff925eb982","trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.010Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# RAG Pipeline","metadata":{"id":"r1Lfz6KJxLEL"}},{"cell_type":"code","source":"# MAIN RAG PIPELINE\n\nclass RAGPipeline:\n    \"\"\"\n    This is the central class that handles:\n    - Loading and chunking documents\n    - Initializing vector and keyword search\n    - Running queries\n    - Generating responses from the LLM\n    - Running full experiment sweeps\n    \"\"\"\n    def __init__(\n        self,\n        document_dir: str,\n        embedding_model: str = DEFAULT_EMBEDDING_MODEL,\n        llm_model: str = DEFAULT_LLM_MODEL,\n        chunk_size: int = DEFAULT_CHUNK_SIZE,\n        chunk_overlap: int = DEFAULT_CHUNK_OVERLAP,\n        device: str = \"cuda\"\n    ):\n        self.document_dir = document_dir\n        self.embedding_model = embedding_model\n        self.llm_model = llm_model\n        self.chunk_size = chunk_size\n        self.chunk_overlap = chunk_overlap\n        self.device = device\n\n        # To store runtime state\n        self.documents = None\n        self.chunks = None\n        self.vectordb = None\n        self.bm25_index = None\n        self.llm = None\n        self.tokenizer = None\n        self.last_retrieved_docs = None  # For evaluation traceability\n\n\n    # ==========================\n    # LOAD & CHUNK DOCUMENTS\n    # ==========================\n    def load_and_process_documents(self):\n        \"\"\"\n        Loads PDF documents and splits them into overlapping chunks.\n        \"\"\"\n        print(\"📄 Loading documents...\")\n        self.documents = load_documents(self.document_dir)\n        print(f\"✅ Loaded {len(self.documents)} document pages.\")\n\n        print(\"🪓 Chunking documents...\")\n        self.chunks = chunk_documents(\n            self.documents,\n            chunk_size=self.chunk_size,\n            chunk_overlap=self.chunk_overlap\n        )\n        print(f\"✅ Created {len(self.chunks)} chunks.\")\n\n        # Add unique IDs to chunks for tracking\n        for i, chunk in enumerate(self.chunks):\n            chunk.metadata[\"chunk_id\"] = i\n\n\n    # ==========================\n    # INITIALIZE RETRIEVAL\n    # ==========================\n    def initialize_retrieval(self):\n        \"\"\"\n        Builds vector store and keyword index for retrieval.\n        \"\"\"\n        if not self.chunks:\n            raise ValueError(\"❌ No chunks found. Run load_and_process_documents() first.\")\n\n        print(\"📦 Creating vector store...\")\n        self.vectordb = create_vector_store(self.chunks, self.embedding_model)\n\n        print(\"🔎 Creating BM25 index...\")\n        self.bm25_index = create_bm25_index(self.chunks)\n\n\n    # ==========================\n    # INITIALIZE LLM\n    # ==========================\n    def initialize_llm(self):\n        \"\"\"\n        Loads the chosen LLM and tokenizer from HuggingFace.\n        \"\"\"\n        print(\"🤖 Loading LLM...\")\n        self.llm, self.tokenizer = initialize_llm(self.llm_model, self.device)\n\n\n    # ==========================\n    # GET LAST RETRIEVED CHUNKS\n    # ==========================\n    def get_last_retrieved_docs(self):\n        \"\"\"\n        Returns the last set of retrieved document chunks (used in evaluation).\n        \"\"\"\n        if self.last_retrieved_docs is None:\n            raise ValueError(\"❌ No retrievals done yet.\")\n        return self.last_retrieved_docs\n\n\n    # ==========================\n    # MAIN QUERY FUNCTION\n    # ==========================\n    def query(\n        self,\n        question: str,\n        search_type: str = DEFAULT_SEARCH_TYPE,  # semantic / keyword / hybrid\n        k: int = DEFAULT_SEARCH_K,\n        semantic_weight: float = 0.5,\n        keyword_weight: float = 0.5,\n        custom_instruction: str = None\n    ) -> str:\n        \"\"\"\n        Executes a full query through the pipeline:\n        - Retrieves chunks\n        - Formats prompt\n        - Calls LLM\n        - Returns answer\n        \"\"\"\n        if not self.vectordb or not self.bm25_index:\n            raise ValueError(\"❌ Retrieval systems not ready. Run initialize_retrieval().\")\n        if not self.llm:\n            raise ValueError(\"❌ LLM not initialized. Run initialize_llm().\")\n\n        # Step 1: Retrieve relevant documents\n        if search_type == \"semantic\":\n            results = semantic_search(question, self.vectordb, k)\n        elif search_type == \"keyword\":\n            results = keyword_search(question, self.bm25_index, self.chunks, k)\n        elif search_type == \"hybrid\":\n            results = hybrid_search(\n                question,\n                self.vectordb,\n                self.bm25_index,\n                self.chunks,\n                k,\n                semantic_weight,\n                keyword_weight\n            )\n        else:\n            raise ValueError(f\"❌ Unknown search type: {search_type}\")\n\n        retrieved_docs = [doc for doc, _ in results]\n        self.last_retrieved_docs = retrieved_docs\n\n        # Step 2: Format prompt\n        prompt = format_rag_prompt(question, retrieved_docs, custom_instruction)\n\n        # Step 3: Generate LLM response\n        return generate_response(prompt, self.llm)\n\n\n    # ==========================\n    # EXPERIMENTATION FUNCTION\n    # ==========================\n    def experiment(\n        self,\n        questions: List[str],\n        gold_answers: List[str],\n        chunk_sizes: List[int],\n        k_values: List[int],\n        search_types: List[str],\n        chunk_overlaps: List[int] = [0, 100, 200]\n    ) -> Dict:\n        \"\"\"\n        Run multiple experiment configurations (varying chunk size, k, search type).\n\n        Args:\n            questions: list of input queries\n            gold_answers: reference answers (used in evaluation)\n            chunk_sizes: different chunk sizes to test\n            k_values: number of results to retrieve\n            search_types: list of retrieval modes\n            chunk_overlaps: amount of content overlap between chunks\n\n        Returns:\n            A dict of results by config\n        \"\"\"\n        results = {}\n\n        for chunk_size in chunk_sizes:\n            for chunk_overlap in chunk_overlaps:\n                self.chunk_size = chunk_size\n                self.chunk_overlap = chunk_overlap\n\n                print(f\"\\n⚙️  Testing: chunk={chunk_size}, overlap={chunk_overlap}\")\n                self.load_and_process_documents()\n                self.initialize_retrieval()\n\n                evaluator = RAGEvaluator(self, self.llm, HuggingFaceEmbeddings(model_name=self.embedding_model))\n\n                for search_type in search_types:\n                    for k in k_values:\n                        config_name = f\"chunk{chunk_size}_overlap{chunk_overlap}_{search_type}_k{k}\"\n                        results[config_name] = {}\n\n                        for question in questions:\n                            try:\n                                answer = self.query(\n                                    question,\n                                    search_type=search_type,\n                                    k=k\n                                )\n                                results[config_name][question] = answer\n\n                                # Run evaluation (with gold answer)\n                                eval_result = evaluator.evaluate_ragas([question], [gold_answers[0]])\n                                print(eval_result[['faithfulness', 'answer_relevancy']])\n\n                                # Visualization + optimization\n                                evaluator.visualize_metrics()\n                                print(\"\\n🧠 Optimization Suggestions:\")\n                                print(evaluator.get_optimization_insights())\n\n                            except Exception as e:\n                                results[config_name][question] = f\"❌ Error: {str(e)}\"\n\n        return results\n\n\n    def grid_search(\n        self,\n        questions: List[str],\n        gold_answers: List[str],\n        chunk_sizes: List[int],\n        k_values: List[int],\n        search_types: List[str],\n        chunk_overlaps: List[int] = [0, 100, 200],\n        semantic_weight: float = 0.5,\n        keyword_weight: float = 0.5,\n        output_csv_path: str = \"rag_grid_search_results.csv\"\n    ) -> Dict:\n        \"\"\"\n        Run grid search over multiple config combinations and log results to CSV.\n    \n        Returns:\n            Dictionary of results.\n        \"\"\"\n        results = []\n        header_written = False\n    \n        # Ensure output directory exists\n        os.makedirs(os.path.dirname(output_csv_path) or \".\", exist_ok=True)\n    \n        with open(output_csv_path, mode='w', newline='', encoding='utf-8') as file:\n            writer = csv.writer(file)\n    \n            for chunk_size in chunk_sizes:\n                for chunk_overlap in chunk_overlaps:\n                    if chunk_overlap >= chunk_size:\n                        continue\n                    self.chunk_size = chunk_size\n                    self.chunk_overlap = chunk_overlap\n    \n                    self.load_and_process_documents()\n                    self.initialize_retrieval()\n    \n                    evaluator = RAGEvaluator(self, self.llm, HuggingFaceEmbeddings(model_name=self.embedding_model))\n    \n                    for search_type in search_types:\n                        for k in k_values:\n                            config_name = f\"chunk{chunk_size}_overlap{chunk_overlap}_{search_type}_k{k}\"\n                            print(f\"\\n🔬 Running Config: {config_name}\")\n    \n                            for i, question in enumerate(questions):\n                                try:\n                                    start_time = time.time()\n    \n                                    # Step 1: Query\n                                    retrieval_start = time.time()\n                                    answer = self.query(\n                                        question=question,\n                                        search_type=search_type,\n                                        k=k,\n                                        semantic_weight=semantic_weight,\n                                        keyword_weight=keyword_weight\n                                    )\n                                    retrieval_end = time.time()\n    \n                                    # Step 2: Evaluation\n                                    eval_df = evaluator.evaluate_ragas([question], [gold_answers[i]])\n                                    eval_row = eval_df.iloc[0].to_dict()\n    \n                                    # Step 3: Timing\n                                    end_time = time.time()\n                                    total_time = end_time - start_time\n                                    retrieval_time = retrieval_end - retrieval_start\n                                    generation_time = total_time - retrieval_time\n\n                                    print(eval_result[['faithfulness', 'answer_relevancy']])\n\n                                    # Visualization + optimization\n                                    evaluator.visualize_metrics()\n                                    print(\"\\n🧠 Optimization Suggestions:\")\n                                    print(evaluator.get_optimization_insights())\n    \n                                    # Step 4: Build result row\n                                    row = {\n                                        \"config\": config_name,\n                                        \"question\": question,\n                                        \"answer\": answer,\n                                        \"chunk_size\": chunk_size,\n                                        \"chunk_overlap\": chunk_overlap,\n                                        \"search_type\": search_type,\n                                        \"top_k\": k,\n                                        \"semantic_weight\": semantic_weight,\n                                        \"keyword_weight\": keyword_weight,\n                                        \"retrieval_time\": round(retrieval_time, 4),\n                                        \"generation_time\": round(generation_time, 4),\n                                        \"total_time\": round(total_time, 4),\n                                        **eval_row\n                                    }\n    \n                                    # Write CSV header if needed\n                                    if not header_written:\n                                        writer.writerow(row.keys())\n                                        header_written = True\n    \n                                    writer.writerow(row.values())\n                                    results.append(row)\n    \n                                except Exception as e:\n                                    print(f\"⚠️ Error in config {config_name} for question '{question}': {e}\")\n                                    writer.writerow([config_name, question, f\"Error: {str(e)}\"])\n    \n        print(f\"\\n✅ All results logged to: {output_csv_path}\")\n        return results","metadata":{"execution":{"execution_failed":"2025-04-18T17:59:25.010Z"},"id":"ebUXkzJ5xLEL","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Running\nhere we now run the code","metadata":{}},{"cell_type":"code","source":"# STEP 1: CREATE EMBEDDINGS & LLM WRAPPER\n\n# Use the same model you defined as DEFAULT_EMBEDDING_MODEL\nembeddings = HuggingFaceEmbeddings(model_name=DEFAULT_EMBEDDING_MODEL)\n\n# Initialize LLM pipeline\ngenerator, tokenizer = initialize_llm(\n    model_name=DEFAULT_LLM_MODEL,     # <-- Use the same LLM constant from above\n    device=\"cuda\",                    # \"cuda\" or \"cpu\"\n    max_new_tokens=300                # <-- You can increase this if responses are too short\n)\n\n# Wrap your generator for LangChain compatibility\nlocal_llm = HuggingFacePipeline(pipeline=generator)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.011Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# STEP 2: INITIALIZE RAG PIPELINE\n\nrag = RAGPipeline(\n    document_dir=DEFAULT_DOCUMENT_DIR,       # <-- uses constant\n    embedding_model=DEFAULT_EMBEDDING_MODEL,\n    llm_model=DEFAULT_LLM_MODEL,\n    chunk_size=DEFAULT_CHUNK_SIZE,\n    chunk_overlap=DEFAULT_CHUNK_OVERLAP,\n    device=\"cuda\"\n)\nrag","metadata":{"execution":{"execution_failed":"2025-04-18T17:59:25.011Z"},"id":"oZT87eroxLEM","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# STEP 3: LOAD DOCUMENTS & PREPARE SYSTEM\n\nrag.load_and_process_documents()\nrag.initialize_retrieval()\nrag.initialize_llm()  # This will use Llama model defined above","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# STEP 4: ASK A SINGLE QUESTION\n\nquestions = [\n    \"What is Dynamic Programming?\"\n    # \"Explain the matrix method in hashing\",\n    # \"What are the key concepts in amortized analysis?\"\n]\n\n# Run query with hybrid search and show result\nanswer = rag.query(\n    questions[0],\n    search_type=DEFAULT_SEARCH_TYPE,\n    k=DEFAULT_SEARCH_K\n)\nprint(f\"\\n🧠 Answer:\\n{answer}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.012Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# STEP 5: PROVIDE GROUND TRUTH FOR EVALUATION (OPTIONAL)\n\ngold_answers = [\n    \"Dynamic Programming is a technique for solving problems by breaking them into overlapping subproblems, storing intermediate results, and combining them to solve the larger problem efficiently.\"\n    # \"Dynamic Programming is a powerful technique that can be used to solve many combinatorial problems in polynomial time for which a naive approach would take exponential time. Dynamic Programming is a general approach to solving problems, much like “divide-and-conquer”, except that the subproblems will overlap.\"\n]","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# STEP 6: RUN AUTOMATIC EVALUATION\n\nevaluator = RAGEvaluator(rag, llm=local_llm, embeddings=embeddings)\nresults_df = evaluator.evaluate_ragas(questions, gold_answers)\nprint(\"\\n📊 Evaluation Results:\\n\", results_df)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize performance\nevaluator.visualize_metrics()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Show optimization tips\nprint(\"\\n🛠️ Suggestions to Improve RAG System:\")\nprint(evaluator.get_optimization_insights())","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-18T17:59:25.018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"experiment_results = rag.grid_search(\n    questions=questions,\n    gold_answers=gold_answers,\n    chunk_sizes=[100, 250, 500, 800, 1000],\n    k_values=[3, 4, 5], \n    search_types=[\"semantic\", \"hybrid\", \"keyword\"],\n    chunk_overlaps=[100, 200],\n    output_csv_path=\"/kaggle/working/rag_grid_log.csv\"\n)","metadata":{"execution":{"execution_failed":"2025-04-18T17:59:25.018Z"},"id":"7_CDByMKxLEO","outputId":"603c57f0-e91b-4827-c259-90a7b7735bf7","trusted":true},"outputs":[],"execution_count":null}]}